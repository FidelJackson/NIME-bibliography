@InProceedings{nime2011-music-Troyer2011,
  author    = {Akito van Troyer, Jason Freeman, Avinash Sastry, Sang Won Lee, Shannon Yao},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  title     = {LOLC},
  year      = {2011},
  address   = {Oslo, Norway},
  editor    = {Kjell Tore Innervik and Ivar Frounberg},
  month     = jun,
  publisher = {Norwegian Academy of Music},
  abstract  = {Program notes:

  In LOLC, the musicians in the laptop orchestra use a textual performance interface, developed specifically for this piece, to create and share rhythmic motives based on a collection of recorded sounds. The environment encourages musicians to share their code with each other, developing an improvisational conversation over time as material is looped, borrowed, and transformed. LOLC was originally created by Akito van Troyer and Jason Freeman and is in active development at the Georgia Tech Center for Music Technology by Jason Freeman, Andrew Colella, Sang Won Lee and Shannon Yao. LOLC is supported by a grant from the National Science Foundation as part of a larger research project on musical improvisation in performance and education (NSF CreativeIT#0855758).

About the performers:

Aaron Albin, Andrew Colella, Sertan Sentürk and Sang Won Lee are current degree candidates or alumni from the Georgia Tech Center for Music Technology. All are focused on exploring new methods of musical interactivity through projects that involve current technology such as the Kinect, swarm robots, creative video games, and current MIR techniques.},
  url       = {https://vimeo.com/26678685},
}

@InProceedings{nime2011-music-Brandtsegg2011,
  author    = {Øyvind Brandtsegg and Carl Haakon Waadeland},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  title     = {Little Soldier Joe},
  year      = {2011},
  address   = {Oslo, Norway},
  editor    = {Kjell Tore Innervik and Ivar Frounberg},
  month     = jun,
  publisher = {Norwegian Academy of Music},
  abstract  = {Program notes:

  The duo Little Soldier Joe uses percussion and live processing to explore thematic and textural ideas that arise in the improvised interplay between these two performers. LSJ uses live sampling and manipulation matter-of-factly as an established manner of music making. The audio manipulation techniques used are based on recent developments in particle synthesis.

About the performers:

Øyvind Brandtsegg: Composer, musician and professor in music technology at NTNU. His focus lies in Compositionally Enabled Instruments, Particle Synthesis and sound installations. Øyvind has performed with the groups Krøyt and Motorpsycho, written music for interactive dance, theatre and TV, and worked as a programmer for other artists. His latest effort in music software programming is the “Hadron Particle Synthesizer”, to be released as a device for “Ableton Live”' and as a VST plug-in.

Carl Haakon Waadeland: Musician, composer and professor in music at NTNU. His main scientific interest lies within empirical rhythm research and the construction of models that simulate rhythm performance. Waadeland has performed and recorded amongst others with Gary Holton & Casino Steel, Warne Marsh, Siris Svale Band, Mikis Theodorakis & Arja Saijonmaa, Dadafon, and Rasmus og Verdens Beste Band. Waadeland published a book and CD on the Norwegian folk drum tradition in 2008.},
  url       = {https://vimeo.com/26680018},
}

@InProceedings{nime2011-music-Lopez2011,
  author    = {Carles López},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  title     = {Reactable},
  year      = {2011},
  address   = {Oslo, Norway},
  editor    = {Kjell Tore Innervik and Ivar Frounberg},
  month     = jun,
  publisher = {Norwegian Academy of Music},
  abstract  = {Program notes:

  The Reactable was conceived in 2003 and was first presented at the International Computer Music Conference (ICMC) 2005 in Barcelona. Since then, the Reactable team has given more than 300 presentations and concerts in 40 countries, turning it into one of the most worldwide acclaimed new musical instruments of the 21st century. Since 2009, the Barcelona spin-off company Reactable Systems has been producing several Reactable models, such as the Reactable Live for traveling musicians and DJs, or its latest incarnation, Reactable mobile for Apple's iPhones and iPads.

About the performers:

Carles López: Musician, producer and DJ born in Barcelona. López has been playing with the Reactable for the last three years. With this instrument he has performed in more than 40 countries, at all kinds of events, clubs and festivals. López also works as a composer for films and contemporary dance.},
  url       = {https://vimeo.com/26678704},
}

@InProceedings{nime2011-music-Selle2011,
  author    = {Jacob Selle and Stefan Weinzierl},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  title     = {Licht \& Hiebe},
  year      = {2011},
  address   = {Oslo, Norway},
  editor    = {Kjell Tore Innervik and Ivar Frounberg},
  month     = jun,
  publisher = {Norwegian Academy of Music},
  abstract  = {Program notes:

  Licht & Hiebe (2010) is the first concert piece for the new Instrument: The ``Hexenkessel'' (witch's cauldron) is a modified 22" timpani that uses LLP technology to turn the drumhead into an intuitive multitouch-interface for the control of live-electronics \& dmx-stage-lights. The multitouch technique goes into symbiosis with a traditional instrument, keeping its acoustic qualities, but opening it to the vast possibilities of interactive multimedia. Besides the control of live-electronics the instrument features an interface to dmx-controlled stage-lights to create a situation of intense intermedial fireworks entirely controlled by the performer. The parts needed for this non-destructive timpani-hack cost less than \$500.

About the performers:

Jacob Sello (1976, Hamburg/Germany) studied Audio Engineering, Systematic Musicology and Multimedia Composition in Hamburg. He is highly interested in the exciting possibilities that arise from the conjunction of traditional acoustic instruments and state-of-the-art technology. Pieces for clarinet controlled RC- helicopters or DJ-driven pneumatically prepared disklavier pieces are the outcome.

Stefan Weinzierl (1985, Günzburg/Germany) is constantly searching for fascinating challenges beyond genre-boundaries; as a drummer in contemporary solo performances, classical ensembles and orchestras as well as in Jazz- and Rock/Pop bands. He graduated in educational sciences in Regensburg and completed the Percussion Master program at the HfMT Hamburg in 2010.},
  url       = {https://vimeo.com/27687788},
}

@InProceedings{nime2011-music-Clayton2011,
  author    = {Joshua Clayton},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  title     = {ROYGBIV},
  year      = {2011},
  address   = {Oslo, Norway},
  editor    = {Kjell Tore Innervik and Ivar Frounberg},
  month     = jun,
  publisher = {Norwegian Academy of Music},
  abstract  = {Program notes:

  Refraction of Your Gaze by Indeterminate Variables (ROYGBIV) is an effort to interface sound and the visible spectrum with digital and analog media. A collage of field recording, synth pad, and mechanical noise, ROYGBIV unfolds as wavelengths of light are read with discrete color sensors. Data is communicated through microcontrollers to custom audio software and a slide projector reproduces images of the natural world. ROYGBIV is concerned with fundamental properties of sensing, perception, and the technologies that mediate such experience. Metaphysical dimensions of color and sound are implied as the projected image and rainbow form a dialectic between reflection and refraction.

About the performers:

Joshua Clayton: New York-based artist whose work occupies a hybrid space of media art and language. His recent projects explore semiotics, mysticism, architecture and the urban landscape, and research-based forms of practice. Joshua has just completed a master's degree in Interactive Telecommunications from New York University.},
  url       = {https://vimeo.com/27690118},
}

@InProceedings{nime2011-music-Stewart2011,
  author    = {Andrew Stewart},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  title     = {With Winds (for soprano t-stick)},
  year      = {2011},
  address   = {Oslo, Norway},
  editor    = {Kjell Tore Innervik and Ivar Frounberg},
  month     = jun,
  publisher = {Norwegian Academy of Music},
  abstract  = {Program notes: The t-sticks grew out of a collaborative project by Joseph Malloch and composer D. Andrew Stewart, at McGill University. The first prototype was completed in 2006. The t-sticks form a family of tubular digital musical instruments, ranging in length from 0.6 metres (soprano) to 1.2 metres (tenor). They have been designed and constructed to allow a large variety of unique interaction techniques. As a result, a significant emphasis is placed on the gestural vocabulary required to manipulate and manoeuvre the instrument. The musical experience for both the performer and audience is characterised by a unique engagement between performer body and instrument.

About the performers: D. Andrew Stewart (Hexagram-MATRALAB, Concordia University, Montreal, Canada): composer, pianist, clarinettist and digital musical instrumentalist. Stewart has been working in the field of music composition since 1994.  Since 2000, he has been pursuing a career in live electronics -- gesture-controlled -- performance, after developing his own sensor-suit.},
  url       = {https://vimeo.com/28226070},
}

@InProceedings{nime2011-music-Mays2011,
  author    = {Tom Mays},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  title     = {L'instant},
  year      = {2011},
  address   = {Oslo, Norway},
  editor    = {Kjell Tore Innervik and Ivar Frounberg},
  month     = jun,
  publisher = {Norwegian Academy of Music},
  abstract  = {Program notes: "L'instant" (2011) : Solo performance for Karlax instrument and laptop. Composed and performed by Tom Mays. Originally an 8 channel tape piece, it was completely re-constructed as a live solo for the composer performing on a Karlax instrument – a gestural controller developed by Da Fact in France (see http://www.dafact.com/). Musically, "L'instant" is a musical interpretation of subatomic instantons, employing rotation and layering of parts who's rhythms and timbres are built out of the combining and crossing of series of numbers... The scenario is roughly “from the big bang to entropy”, and a “surround sound” 5.1 diffusion space is critical to the sense of immersion within the rotating sound objects and textures.

About the performer: Tom Mays: composer, computer musician and teacher, teaches at the National Superior Conservatory of Music in Paris, and is currently working on PhD at the University of Paris 8 with Horacio Vaggione. He is especially interested in gestural performance of real-time computer systems for both written and improvised music, as well as in interaction between music and video.},
  url       = {https://vimeo.com/28238543},
}

@InProceedings{nime2011-music-Dupuis2011,
  author    = {Alexander Dupuis},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  title     = {All Hail the Dawn},
  year      = {2011},
  address   = {Oslo, Norway},
  editor    = {Kjell Tore Innervik and Ivar Frounberg},
  month     = jun,
  publisher = {Norwegian Academy of Music},
  abstract  = {Program notes:

  An interactive audiovisual feedback loop forms the basis of All Hail the Dawn. The instrument contains two simple light-sensitive oscillators.  A crude spectral analysis in Max/MSP is used to filter the oscillators as well as looped buffers recorded from the instrument.  A matrix of the spectral analysis, interactively altered in Jitter using audio data, is projected back onto the instrument and performer as a series of shifting patterns.  This setup allows both the graphics and sound to drive each other, creating an evolving audiovisual relationship sensitive to slight changes in position, sound or processing.

About the performers:

Alexander Dupuis: composer, performer, and multimedia artist. His work involves live electronics and guitar, real-time graphics and 3D animation, feedback systems and audiovisual installations. He graduated from Brown University in 2010, and is currently working towards his Masters Degree in the Digital Musics program at Dartmouth College.},
  url       = {https://vimeo.com/27691545},
}

@InProceedings{nime2011-music-Nagashima2011,
  author    = {Yoichi Nagashima},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  title     = {Ural Power},
  year      = {2011},
  address   = {Oslo, Norway},
  editor    = {Kjell Tore Innervik and Ivar Frounberg},
  month     = jun,
  publisher = {Norwegian Academy of Music},
  abstract  = {Program notes: Live computer music (multimedia) work, composed in 2010 and premiered in Russia. For this work, the composer developed a new interface system for musical expression. The new interface has 8 channels of infrared-ray distance sensors. This instrument is set up with two mic-stands on the stage. The performer also wears the specially developed instrument called MiniBioMuse-III which is 16 channels EMG sensor of the performance. The graphic part of this work is real-time OpenGL 3D graphics, which is live-controlled by the performance. This work is programmed in Max/MSP/jitter environment.

About the performer: Yoichi Nagashima: composer/researcher/PE, was born in 1958 in Japan. Since 1991 he has been the director of the Art & Science Laboratory in Hamamatsu, Japan. He is a professor of Shizouka University of Art and Culture, Faculty of Design, Department of Art and Science. He was the General Chair of NIME04.},
  url       = {https://vimeo.com/27731875},
}

@InProceedings{nime2011-music-EPtrio–ErikaDonald2011,
  author    = {EP trio – Erika Donald, Ben Duinker and Eliot Britton},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  title     = {Television Sky},
  year      = {2011},
  address   = {Oslo, Norway},
  editor    = {Kjell Tore Innervik and Ivar Frounberg},
  month     = jun,
  publisher = {Norwegian Academy of Music},
  abstract  = {Program notes: Television Sky is a three-movement work composed by Eliot Britton. The movements (Channels 1, 2, 3) deal with various musical and physical elements that figure prominently in the EP trio's research: Gesture, Texture, and Rhythm. Each movement adopts a different approach to organizing sounds; these provide unique arenas to explore communication, expression, and synchronization issues arising in an electroacoustic chamber music ensemble.

About the performer: EP trio is a multi-faceted research group and performing ensemble. It is comprised of cellist Erika Donald, percussionist Ben Duinker, and composer/ turntablist Eliot Britton. They are based at McGill University in Montreal, Canada where they enjoy support from the Centre for Interdisciplinary Research in Music Media and Technology (CIRMMT).},
  url       = {https://vimeo.com/28241338},
}

@InProceedings{nime2011-music-SarahTaylor2011,
  author    = {Sarah Taylor, Maurizio Goina and Pietro Polotti},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  title     = {Body Jockey},
  year      = {2011},
  address   = {Oslo, Norway},
  editor    = {Kjell Tore Innervik and Ivar Frounberg},
  month     = jun,
  publisher = {Norwegian Academy of Music},
  abstract  = {About the performers:

Sarah Taylor: Dancer, Choreographer trained at the Australian Ballet School (Degree in Dance), in Classical, Cunningham and Graham, Scholarship student to Martha Graham school in New York. Currently working with Cesc Gelabert, for the 2011 Grec Festival, Barcelona.

Maurizio Goina: Viola player and an audio-visual composer. Currently he is affiliated with the School of Music and New Technologies of the Conservatory of Trieste where he is developing, together with Pietro Polotti and with the collaboration of Sarah Taylor, the EGGS system for gesture sonification.

Pietro Polotti: Studied piano, composition and electronic music. He has a degree in physics from the University of Trieste. In 2002, he obtained a Ph.D. in Communication Systems from the EPFL, Switzerland. Presently, he teaches Electronic Music at the Conservatory Tartini of Trieste, Italy. He has been part of the EGGS project since 2008.},
  url       = {http://www.nime.org/proceedings/2019/nime2019_music001.pdf},
}

@InProceedings{nime2011-music-Nicolls2011,
  author    = {Sarah Nicolls and Nick Gillian},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  title     = {Improvisation for piano + motion capture system},
  year      = {2011},
  address   = {Oslo, Norway},
  editor    = {Kjell Tore Innervik and Ivar Frounberg},
  month     = jun,
  publisher = {Norwegian Academy of Music},
  abstract  = {Program notes:
  SN: I wanted to get at the closest relationship possible between my hands and the resulting sound. Having worked with sampling and complex processing and various sensors such as EMG, motion capture with live sound as the source seemed a way to really get inside an improvisation system that was really live and really intuitive. You can judge for yourselves!,

NG: Sarah's movements are sensed using a Kinect 3D motion capture device and the gestures are recognised in real-time using the SEC, a machine learning toolbox that has been specifically developed for musician-computer interaction.

About the performers:

Sarah Nicolls UK-based experimental pianist and inventor of `Inside-out piano'; collaborative researcher with e.g. Atau Tanaka, PA Tremblay; concerts e.g. world premieres of Larry Goves' Piano Concerto, Richard Barrett's Mesopotamia/London Sinfonietta/BBC Radio; article in LMJ20; Senior Lecturer at Brunel University; funding: Arts and Humanities Research Council (AHRC), Brunel Research Initiative and Enterprise Fund (BRIEF), Arts Council England.

Nick Gillian Post-doctoral researcher currently working on an E.U. project entitled SIEMPRE at the Sonic Arts Research Centre, Belfast. Nick recently completed his PhD in Gesture Recognition for Musician-Computer Interaction under the supervision of R. Benjamin Knapp and Sile O'Modhrain. His interests are in machine learning and pattern recognition and applying these techniques to enable real-time musician-computer interaction.},
  url       = {https://vimeo.com/26678719},
}

@InProceedings{nime2011-music-Hayes2011,
  author    = {Lauren Sarah Hayes and Christos Michalakos},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  title     = {Socks and Ammo},
  year      = {2011},
  address   = {Oslo, Norway},
  editor    = {Kjell Tore Innervik and Ivar Frounberg},
  month     = jun,
  publisher = {Norwegian Academy of Music},
  abstract  = {Performer notes:
  Socks and Ammo for piano, percussion and live electronics, is a new work investigating novel methods of communication between laptop and performer, as well as performer and performer, in an improvisational setting. Enhancing traditional aural and visual cues, a network is established between laptops, providing direction and suggestion to and between performers. Tactile feedback is provided to performers in the form of tiny vibrations on the skin, opening up a further, yet covert, channel of information to transmit signals and cues, allowing for a more informed and focused performance.

About the performers:

Lauren Sarah Hayes: Composer and performer from Glasgow. Her recent practice focuses on realizing compositions for piano and live electronics, which unify extended technique, bespoke software and instrument augmentation. Undertaken at the University of Edinburgh, her research investigates audio-haptic relationships as performance strategies for performers of digital music.

Christos Michalakos: Composer and improviser from northern Greece. Working predominantly with percussion and live electronics, his music explores relationships between acoustic and electronic sound worlds, through an examination of methods for developing and augmenting his drum kit, forming part of his PhD research at the University of Edinburgh.

===  Recorded at:

11th International Conference on New Interfaces for Musical Expression. 30 May - 1 June 2011, Oslo, Norway.

http://www.nime2011.org},
  url       = {https://vimeo.com/26629807},
}

@InProceedings{nime2011-music-PaulStapleton2011,
  author    = {Paul Stapleton, Caroline Pugh, Adnan Marquez-Borbon and Cavan Fyans},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  title     = {E=MCH},
  year      = {2011},
  address   = {Oslo, Norway},
  editor    = {Kjell Tore Innervik and Ivar Frounberg},
  month     = jun,
  publisher = {Norwegian Academy of Music},
  abstract  = {About the performers:

E=MCH is a recently formed quartet featuring Belfast-based improvisers Paul Stapleton (BoSS \& Postcard Weevil), Caroline Pugh (Voice \& Analogue Cassette Decks, Zero-input Mixer), Adnan Marquez-Borbon (Feedback Bass Clarinet, Recording Modules \& Delay Lines) and Cavan Fyans (DIY Electronics). Memories, distortions of time and place, echoes from analogue delay lengths, solid state samplers, and modified vinyl all help shape the fabric of the music in response to its larger ecology. ``Okay so making instruments and playing on them is not new, can't really see that there is any new thought about how why and what here, but the sound sculpture looks nice.'' --- Cosmopolitan

Paul Stapleton: Sound artist, improviser and writer originally from Southern California, currently lecturing at the Sonic Arts Research Centre in Belfast (SARC). Paul designs and performs with a variety of custom made metallic sound sculptures, electronics and found objects in locations ranging from impro clubs in Cork to abandoned beaches on Vancouver Island.

Caroline Pugh: Scottish vocalist and performance artist. She deviously borrows analogue technologies and oral histories to create performances that present imagined constructions of traditional and popular culture.  With a background in both folk music and improvisation, she collaborates with people from any discipline and performs in a wide variety of venues including folk clubs, arts venues and cinemas.

Adnan Marquez-Borbon: Saxophonist, improviser, computer musician, and composer, currently a PhD student at SARC. His research emphasis is on the roles of learning models and skill development in the design of digital musical instruments. As a musician, his music focuses on improvisation and the electronic manipulation of sounds in real-time.

Cavan Fyans: PhD research student, instrument builder, noise maker \& improviser. Currently located at SARC, Cavan's research examines the spectator's cognition of interaction and performance in communicative interactions with technology. Cavan also devotes time to developing new and innovative ways of breaking cheap electronic toys (Circuit Bending) and (re)constructing circuitry for sonic creation (Hardware Hacking).},
  url       = {https://vimeo.com/26620232},
}

@InProceedings{nime2011-music-Alden2011,
  author    = {Christopher Alden},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  title     = {REMI Sings},
  year      = {2011},
  address   = {Oslo, Norway},
  editor    = {Kjell Tore Innervik and Ivar Frounberg},
  month     = jun,
  publisher = {Norwegian Academy of Music},
  abstract  = {Program notes:
  REMI Sings is an electroacoustic performance for the bio-inspired Rhizomatic Experimental Musical Interface (REMI) and accordion. REMI is an interactive networked musical organism that receives sonic input from its environment, processes it based on the ever changing structure of its interior network, and generates a unique musical output. This rhizomatic network is a software structure modelled after the functioning and growth patterns of biological rhizomes, specifically the mycorrhizal association that form vital nutrient pathways for the majority of the planet's land-plant ecosystems. The performance REMI Sings highlights this interface's interactive nature, creating a dialogue between human performer and non-human musical intelligence.

About the performer:

Christopher Alden: Composer, programmer, and instrumentalist currently studying at New York University's Interactive Telecommunications Program, where his research focuses on interactive music systems for composition and performance. Before ITP, he received his undergraduate degree in Music Theory and Composition at NYU where he studied composition under Marc Antonio-Consoli},
  url       = {https://vimeo.com/26619152},
}

@InProceedings{nime2011-music-Schwarz2011,
  author    = {Diemo Schwarz and Victoria Johnson},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  title     = {Suspended Beginnings},
  year      = {2011},
  address   = {Oslo, Norway},
  editor    = {Kjell Tore Innervik and Ivar Frounberg},
  month     = jun,
  publisher = {Norwegian Academy of Music},
  abstract  = {Program notes:

  The performance between electric violinist Victoria Johnson and Diemo Schwarz playing his interactive corpus-based concatenative synthesis software CataRT is an improvisation with two brains and four hands controlling one shared symbolic instrument, the sound space, built-up from nothing and nourished in unplanned ways by the sound of the instrument, explored and consumed with whatever the live instant filled it with. It creates a symbiotic relationship between the player of the instrument and that of the software. Live corpus-based concatenative synthesis permits here a new approach to improvisation, where sound from an instrument is recontextualised by interactive, gesture-controlled software. Not knowing what can happen is an integral part of the performance.

About the performers:

Victoria Johnson works with electric violin, live electronics, improvisation and musical technological issues in her artistic work. Trained as a classical violinist in Oslo, Vienna and London, she gave her debut recital in Oslo in 1995. She has established herself internationally as a soloist, chamber musician and improviser in contemporary, improvised and experimental, cross-disciplinary music and art.

Diemo Schwarz: Researcher and developer at Ircam, composer of electronic music, and musician on drums and laptop with gestural controllers. His compositions and live performances, in solo as Mean Time Between Failure, or improvising with other musicians, explore the possibilities of corpus-based concatenative synthesis to re-contextualise any sound source by rearranging sound units into a new musical framework using interactive navigation through a timbral space.},
  url       = {https://vimeo.com/26679877},
}

@InProceedings{nime2011-music-JasonDixon2011,
  author    = {Jason Dixon, Tom Davis, Jason Geistweidt and Alain B. Renaud},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  title     = {The Loop},
  year      = {2011},
  address   = {Oslo, Norway},
  editor    = {Kjell Tore Innervik and Ivar Frounberg},
  month     = jun,
  publisher = {Norwegian Academy of Music},
  abstract  = {Program notes:

  The Loop explores the possibilities of co-located performance, decentralized composition, and the acoustics of network. This performance begins with a brief improvisation presenting acoustic sources to excite the network. This material is shared, transformed, and reintroduced into the composition. This process continues through successive generations until a predetermined time or a point at which the composition naturally concludes. The result is an integrated meta-instrument and an emergent composition, with no one artist being the sole performer or composer. Remote participants are represented locally by a mono speaker enabling the audiences to hear the transformation of audio through the networked instrument.

About the performers:

Jason Dixon: Irish composer currently based in Norwich where he is in the process of completing his PhD in composition. His work explores issues of language, perception and memory in music. More recently he has been focusing on the Irish storytelling tradition and its place in contemporary Ireland.

Tom Davis: Digital artist working mainly in the medium of sound installation. His practice and theory based output involves the creation of technology led environments for interaction. Davis is currently a lecturer at the University of Bournemouth and holds a PhD from the Sonic Arts Research Centre, Belfast.

Jason Geistweidt: Sound artist based at the University or Tromsø, Norway, researching mixed-reality stages and performance systems. He is a former faculty member of Interactive Arts and Media department at Columbia College Chicago. He holds PhD in electro-acoustic composition from the Sonic Arts Research Centre, Queens University, Belfast.

Alain B. Renaud: Alain's research focuses on networked music performance systems with an emphasis on the creation of strategies to interact over a network musically and the notion of shared networked acoustic spaces. He is a lecturer in at Bournemouth University, England and holds a PhD from the Sonic Arts Research Centre.},
  url       = {https://vimeo.com/26679893},
}

@InProceedings{nime2011-music-Zappi2011,
  author    = {Victor Zappi and Dario Mazzanti},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  title     = {Dissonance},
  year      = {2011},
  address   = {Oslo, Norway},
  editor    = {Kjell Tore Innervik and Ivar Frounberg},
  month     = jun,
  publisher = {Norwegian Academy of Music},
  abstract  = {Program notes:
  Dissonance is an audio/visual performance in which a progressive soundtrack is created along with the exploration of an interactive virtual environment. While real instrument--generated music animates the projected worlds, the two performers are allowed to physically interact with virtual objects, changing their position, shape and color to control music and create new sounds. As the journey continues and the environment introduces new elements and new metaphors, performers are driven to explore the sonic laws that rule each scenario. Spectators wearing 3D glasses perceive the virtual environment as moving out of the screen and embracing the artists, in choreographies where real and virtual world literally overlap.

About the performers:

Victor Zappi: PhD student and a new media artist. His research focuses on Virtual Reality and its applications in art and live performances.

Dario Mazzanti: computer science engineer and multi-instrumentalist composer. He enjoys writing, recording and playing music combining his artistic streak with his interest for technology.},
  url       = {https://vimeo.com/26616186},
}

@InProceedings{nime2011-music-Nowitz2011,
  author    = {Alex Nowitz},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  title     = {The Shells},
  year      = {2011},
  address   = {Oslo, Norway},
  editor    = {Kjell Tore Innervik and Ivar Frounberg},
  month     = jun,
  publisher = {Norwegian Academy of Music},
  abstract  = {Program notes:

  Since 2008 I have been performing and composing music for voice and live-electronics using two Wii-remotes as gestural controllers. The live-electronics function in two ways: as an extension of my voice and as an instrument as well. The music creation is mainly based on live-sampling the voice. I also use pre-recorded sounds and my own compositions. In addition, since the beginning of 2010 we have been developing a new instrument, which goes beyond the technical possibilities of the Wii-controllers. I call this instrument the Shells. Besides motion sensors there are three more continuous controllers available: a pressure sensor, a joystick control and ultrasound for distance measurement.

About the performers:

Alex Nowitz: Composer of vocal, chamber and electronic music as well as music for dance, theatre and opera. Furthermore, he is a voice artist, whistling and singing virtuoso who is classically trained as tenor and countertenor and presents a wide array of diverse and extended techniques. He has been artist in residence at STEIM, Amsterdam, since 2010.},
  url       = {https://vimeo.com/26661484},
}

@InProceedings{nime2011-music-Guillamat2011,
  author    = {Julien Guillamat, Charles Céleste Hutchins, Shelly Knotts, Norah Lorway, Jorge Garcia Moncada, Chris Tarren},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  title     = {BiLE (Birmingham Laptop Ensemble)},
  year      = {2011},
  address   = {Oslo, Norway},
  editor    = {Kjell Tore Innervik and Ivar Frounberg},
  month     = jun,
  publisher = {Norwegian Academy of Music},
  abstract  = {Program notes:
  An open playground for laptop improvisation and performance. BiLE's performance will focus on semi-structured improvisation, with players creating and manipulating sound using a variety of motion capture devices - iPhones, Wiimotes, and Xbox Kinect. The data captured by each device, along with analysed musical parameters, will be sent out over the shared network, to be used by each performer as they see fit. The aim is to allow players to latch onto other members of the group by mapping the shared data to their own software parameters, creating moments of convergence between the ensemble. BiLE takes an `instrumental' approach to performance, with each performer having their own speaker, sonic identity and spatial location.

About the performers:

BiLE (Birmingham Laptop Ensemble): A collaborative group of six composers, brought together through their shared interest in live performance and improvisation. BiLE has an open and inclusive attitude towards experimentation with sound, and draws on the members' wide-ranging musical backgrounds.},
  url       = {https://vimeo.com/26619928},
}

@InProceedings{nime2011-music-Quay2011,
  author    = {Yago de Quay and Ståle Skogstad},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  title     = {Where Art Thou?: Dance Jockey},
  year      = {2011},
  address   = {Oslo, Norway},
  editor    = {Kjell Tore Innervik and Ivar Frounberg},
  month     = jun,
  publisher = {Norwegian Academy of Music},
  abstract  = {Program notes:
  As artists, we have learned that throughout the history of mankind music and technology have co-evolved, shaping --- and being shaped by --- human expression and creativity. The variety and intricacy of these recombination processes contribute profoundly to the current diversity of performative structures and aesthetics within the arts. Where art Thou? is a 15 minute theatrical performance where sounds are controlled by sensors on the dancer's body. Blending a mixture of electronic music and sound effects with dance and acting, this novel act refocuses sensors from simplistic action-to-sound to contextualized aesthetic and dramatic expression. The name reflects the itinerant quality of the stage character as he travels through a world of sounds.

About the performers:

Yago de Quay: Interactive media artist, musician and researcher based in Porto. His numerous installations and performances focus on user participation contributing to modify the art piece itself. They always have a strong sonic component and combine technologies to help create new modes of expression. Yago is currently finishing his M.Sc. in Sound Design and Interactive Music at the Faculty of Engineering, University of Porto.

Ståle Skogstad: PhD student in the fourMs group at the University of Oslo. His research is focused on using real-time full-body motion capture technology for musical interaction. This includes real-time feature extraction from full body motion capture data and technical studies of motion capture technologies. He is currently working with the Xsens MVN inertial sensor suit.},
  url       = {https://vimeo.com/26619980},
}

@InProceedings{nime2011-music-Sciajno2011,
  author    = {Domenico Sciajno},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  title     = {Sonolume},
  year      = {2011},
  address   = {Oslo, Norway},
  editor    = {Kjell Tore Innervik and Ivar Frounberg},
  month     = jun,
  publisher = {Norwegian Academy of Music},
  abstract  = {Program notes:
  In this AV performance, images and sound interact: the basic elements of the images (brightness, color, saturation, hue, dislocation and relocation) are sensitive to the fundamental parameters of the sound being generated at that moment. Sound waves (also controlled by light waves during the performance) cross the physical world and alter the data stream that gives life to digital video in the same way that molecules are transformed by the sound contracting and expanding air particles in space.

About the performers:

Domenico Sciajno: Double bass player and composer of acoustic and electronic music. Thanks to his interest in improvisation and the influence of academic education, his research currently focuses on the creative possibilities provided by the interaction between acoustic instruments, indeterminacy factors and live processing by electronic devices or computers.},
  url       = {https://vimeo.com/26679879},
}

@InProceedings{nime2011-music-Aase2011,
  author    = {Tone Åse, Siri Gjære, Live Maria Roggen, Heidi Skjerve, Ingrid Lode, Kirsti Huke, Anita Kaasbøll, Silje R. Karlsen},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  title     = {Trondheim Voices},
  year      = {2011},
  address   = {Oslo, Norway},
  editor    = {Kjell Tore Innervik and Ivar Frounberg},
  month     = jun,
  publisher = {Norwegian Academy of Music},
  abstract  = {Program notes:

  Trondheim Voices is in this performance exploring a new tool in their work with voice sound and improvisation. The ensemble is working with a tracking system for sound positioning to enable a given singer's position on stage to directly influence the sound processing, both spatialisation and effects. Through their improvisations and compositions they are exploring: a) The effect of the sound “following”' the singers' movements on stage. b) The flexible use of processed voice sound within the big vocal ensemble, through the control each singer gets over the sound output by moving on stage. c) The visualization of choices and changes regarding sound, both for the performer and the audience, through the movements of each singer on stage.

About the performers:

Trondheim Voices Professional ensemble, working with the endless possibilities within the field of vocal improvisation, to find new expressions and new music. Consisting of individual soloists, Trondheim Voices wishes to develop what happens when the unique soloist quality of each singer is set to interact with each other, and to find the collective sound and feeling. All of the singers are educated at NTNU, Trondheim, Norway.

Sound: Asle Karstad. Tracking system: John Torger Skjelstad},
  url       = {https://vimeo.com/26680007},
}

@InProceedings{nime2011-music-Hsu2011,
  author    = {Bill Hsu and Alain Crevoisier},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  title     = {Interstices AP},
  year      = {2011},
  address   = {Oslo, Norway},
  editor    = {Kjell Tore Innervik and Ivar Frounberg},
  month     = jun,
  publisher = {Norwegian Academy of Music},
  abstract  = {Program notes:

  Interstices AP is a structured audio-visual solo improvisation, using the multitouch Airplane Controller to manipulate live electronic sound and interactive animations. During the piece, Bill Hsu will be using the Airplane Controller in combination with his PSHIVA particle system software, to synthesize and interact with generative sound and animations. The visual component of Interstices AP is a physics-based simulation of a particle system. Particles, images and other components interact with physical gestures in a fluid like system; the results resemble asymmetric, constantly evolving Rorschach blots that open up a wide range of visual associations. For more details, see Bill Hsu's poster in the conference proceedings.

About the performers:

Bill Hsu: Associate Professor of Computer Science at San Francisco State University. His work with real-time audiovisual performance systems has been presented at (among others) SMC 2009 (Porto), Harvestworks Festival 2009 (New York), Fete Quaqua 2008 (London), MIX Festival 2007 and 2009 (New York), and Stimme+ 2006 (Karlsruhe).

Alain Crevoisier: Senior researcher at the Music Conservatory of Geneva, Switzerland. He is the founder of Future-instruments.net, a collaborative research network active in the field of new musical interfaces and interactive technologies. The latest realization is the Airplane controller, a portable system that makes possible to transform any flat surface, into a multitouch interface.},
  url       = {https://vimeo.com/26629820},
}

@InProceedings{nime2011-music-Hsu2011a,
  author    = {Bill Hsu, Håvard Skaset, Guro Skumsnes Moe},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  title     = {Flayed/Flock},
  year      = {2011},
  address   = {Oslo, Norway},
  editor    = {Kjell Tore Innervik and Ivar Frounberg},
  month     = jun,
  publisher = {Norwegian Academy of Music},
  abstract  = {Performer notes:

  Flayed/Flock is a structured audio-visual improvisation for three musicians, utilizing live acoustic and electronic sound and interactive animations. The visual component of Flayed/Flock is an enhanced flocking simulation that interacts with real-time audio from the performance of improvising musicians. Abstract patterns develop out of the flocking behavior; the flocks are also able to coalesce into well-defined symbols and forms such as crescents and stars, all while moving in a natural-looking manner consistent with flocking behavior. For more details, see Bill Hsu's poster in the conference proceedings.

About the performers:

Bill Hsu: Associate Professor of Computer Science at San Francisco State University. His work with real-time audiovisual performance systems has been presented at (among others) SMC 2009 (Porto), Harvestworks Festival 2009 (New York), Fete Quaqua 2008 (London), MIX Festival 2007 and 2009 (New York), and Stimme+ 2006 (Karlsruhe).

Håvard Skaset (guitar) and Guro Skumsnes Moe (bass): The Oslo-based duo works intensively in the borders between improv, noise and rock. Skaset and Moe play in bands including Bluefaced People, Art Directors, Sult, Mirror Trio, SEKSTETT, Telling Stories About Trees and MOE. They have been working with Christian Wolff, Pauline Oliveros, Fred Frith, Ikue Mori, Okkyung Lee, Frode Gjerstad and many more.},
  url       = {https://vimeo.com/26629835},
}

@InProceedings{nime2011-music-IvicaIcoBukvicDirector2011,
  author    = {Ivica Ico Bukvic (Director), John Elder, Hillary Guilliams, Bennett Layman, David Mudre, Steven Querry, Philip Seward, Andrew Street, Elizabeth Ullrich and Adam Wirdzek},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  title     = {L2Ork},
  year      = {2011},
  address   = {Oslo, Norway},
  editor    = {Kjell Tore Innervik and Ivar Frounberg},
  month     = jun,
  publisher = {Norwegian Academy of Music},
  abstract  = {Program notes:
  13 (Ivica Ico Bukvic): is a game of prime numbers and primal instincts pitting timbre against rhythm. Driven by conductor's oversight over an array of performer-specific and ensemble-wide parameters, a networked ensemble acts as one large meta-tracker where each individual performer contributes its own gesture-driven motives or tracks. The ensuing meta-tracker texture is superimposed against improvised acoustic percussion in a search of a meaningful discourse and ultimately musical synergy.

  Serene (Ivica Ico Bukvic): ...the one moment in the day when the world melts away and we catch a glimpse of life that just is... a celebration of this moment through juxtaposition of Taiji (Tai Chi Chuan) choreography and music...

 Citadel for soprano and L2Ork (Ivica Ico Bukvic) draws inspiration from a famous poem "Himna Slobodi" (Hymn to Freedom) by the 17th century Croatian poet Ivan Gundulic. As the first piece ever written for the newfound ensemble, it relies upon pervasive tonality, in many ways posing as an electronic counterpart to a traditional string ensemble. Using the infinite-bow metaphor to create lush tonal harmonies the piece forms a compelling aural foundation for a lyrical showcase of soloist's vocal talent.

=== About the performers:

L2Ork: Founded by Dr. Ivica Ico Bukvic in May 2009, is part of the latest interdisciplinary initiative by the Virginia Tech Music Department's Digital Interactive Sound \& Intermedia Studio (DISIS). As an emerging contemporary intermedia ensemble with a uniquely open design, L2Ork thrives upon the quintessential form of collaboration found in the western classical orchestra and its cross-pollination with increasingly accessible human-computer interaction technologies for the purpose of exploring expressive power of gesture, communal interaction, discipline-agnostic environment, and the multidimensionality of arts.

Members: Ivica Ico Bukvic (Director), John Elder, Hillary Guilliams, Bennett Layman, David Mudre, Steven Querry, Philip Seward, Andrew Street, Elizabeth Ullrich and Adam Wirdzek

===  Recorded at:

11th International Conference on New Interfaces for Musical Expression. 30 May - 1 June 2011, Oslo, Norway.

http://www.nime2011.org
About the performers:

L2Ork Founded by Dr. Ivica Ico Bukvic in May 2009, is part of the latest interdisciplinary initiative by the Virginia Tech Music Department's Digital Interactive Sound & Intermedia Studio (DISIS). As an emerging contemporary intermedia ensemble with a uniquely open design, L2Ork thrives upon the quintessential form of collaboration found in the western classical orchestra and its cross-pollination with increasingly accessible human-computer interaction technologies for the purpose of exploring expressive power of gesture, communal interaction, discipline-agnostic environment, and the multidimensionality of arts.

Members: Ivica Ico Bukvic (Director), John Elder, Hillary Guilliams, Bennett Layman, David Mudre, Steven Querry, Philip Seward, Andrew Street, Elizabeth Ullrich and Adam Wirdzek},
  url       = {https://vimeo.com/26678669},
  url2      = {https://vimeo.com/26678662},
  url3      = {https://vimeo.com/26643771},
}

@InProceedings{nime2011-music-Bokowiec2011,
  author    = {Mark Bokowiec and Julie Wilson-Bokowiec},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  title     = {V'Oct(Ritual)},
  year      = {2011},
  address   = {Oslo, Norway},
  editor    = {Kjell Tore Innervik and Ivar Frounberg},
  month     = jun,
  publisher = {Norwegian Academy of Music},
  abstract  = {Program notes: V'Oct(Ritual) places the audience inside a circular liminal space of sonic evocation  and features the Bodycoder System© the first generation of which was developed by the artists in 1995.  The Bodycoder interface is a flexible sensor array worn on the body of a performer that sends data generated by movement to an MSP environment via radio. All vocalisations, decision making, navigation of the MSP environment and qualities of expressivity are selected, initiated and manipulated by the performer, uniquely, this also includes access to gestural control of live 8-channel spatialization.  This piece is fully scored with few moments of improvisation.

About the performers: Julie Wilson-Bokowiec: has created new works in opera/music theatre, contemporary dance and theatre and has worked with Lindsey Kemp, Genesis P-Orridge, Psychic TV and Hermann Nitsch.  Julie is a Research Fellow at CeReNem (Centre for Research in New Music) at the University of Huddersfield.
Mark Bokowiec: is the manager of the electroacoustic music studios and the Spacialization and Interactive Research Lab at the University of Huddersfield where he also lectures in interactive performance, interface design and composition.  Mark began creating work with interactive technologies in 1995.},
  url       = {https://vimeo.com/27694214},
}

@InProceedings{nime2011-music-Shiraishi2011,
  author    = {Satoshi Shiraishi and Alo Allik},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  title     = {mikro:strukt},
  year      = {2011},
  address   = {Oslo, Norway},
  editor    = {Kjell Tore Innervik and Ivar Frounberg},
  month     = jun,
  publisher = {Norwegian Academy of Music},
  abstract  = {Program notes:

  mikro:strukt is a collaborative performance in which the custom-built e-clambone provides an acoustic source for the ensuing audiovisual environment. E-clambone is custom-built electronic instrument that consists of an aerophone supplied with haptic sensors and digital signal processing algorithms. The performance seeks to integrate elements of electro-acoustic improvisation, timbre composition and artificial intelligence based approach to autonomous audiovisual composition and explore micro level timbre composition in real time.

About the performers:

Satoshi Shiraishi: Electro-acoustic instrument designer/performer from Japan, currently living in The Hague, The Netherlands. He originally started his music carrier as a rock guitarist. After the meeting with computer music, he moved to The Netherlands to pursue his own way of playing computer generated sound on a stage.

Alo Allik: (Estonia) has a musically and geographically restless lifestyle, which has taken him through diverse musical worlds including DJ-ing and producing electronic dance music, live laptop jams, electroacoustic composition, free improvisation, audiovisual installations and performances.},
  url       = {https://vimeo.com/27694202},
}

@InProceedings{nime2011-music-Overholt2011,
  author    = {Dan Overholt and Lars Grausgaard},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  title     = {Study No. 1 for Overtone Fiddle},
  year      = {2011},
  address   = {Oslo, Norway},
  editor    = {Kjell Tore Innervik and Ivar Frounberg},
  month     = jun,
  publisher = {Norwegian Academy of Music},
  abstract  = {Program notes:

  This generative / improvisatory work uses an iPod Touch and a tactile sound transducer attached to the Overtone Fiddle's resonant body as a mobile system to lay out a variety of animated and transformed sound sources over time.

About the performers:

Dan Overholt: Associate Professor in the Department of Architecture, Design and Media Technology at Aalborg University, Denmark. He received a PhD in Media Arts and Technology from the University of California, Santa Barbara, a M.S. from the MIT Media Lab, and studied Music and Electronics Engineering and at CSU, Chico. As a musician, he composes and performs internationally with experimental human-computer interfaces and musical signal processing algorithms.

Lars Graugaard: Free-lance composer, laptop performer and researcher. He holds a PhD in Artistic and Technological Challenges of Interactive Music from Oxford Brookes University and a MS in flute performance from the Royal Danish Academy of Music. His main interest is the systematic study of music's expressive capacity applied to score composing, realtime interactive performance, generative and emergent music.},
  url       = {https://vimeo.com/26661494},
}

@InProceedings{nime2011-music-DougVanNort2011,
  author    = {Doug Van Nort, Pauline Oliveros and Jonas Braasch},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  title     = {Distributed Composition #1},
  year      = {2011},
  address   = {Oslo, Norway},
  editor    = {Kjell Tore Innervik and Ivar Frounberg},
  month     = jun,
  publisher = {Norwegian Academy of Music},
  abstract  = {Program notes:

  This piece is written in consideration of two distinct paradigms: telematic music performance and human-machine improvisation. Specifically this work is a structured improvisation for three humans and one intelligent agent, being constrained by sections that determine which pairing (duos, trios) of performers are active. Instrumentation also changes between sections in a way that blurs the line of agency and intent between acoustic human performers, laptop tablet-based human performer, and agent improviser, as the two remote (NY, Stanford) acoustic performers (v-accordion, soprano saxophone) engage with the on-stage laptop performer (GREIS system) and ambient presence of the agent performer (spatialization, loops, textures).

About the performers:

Doug Van Nort: Experimental musician and digital music researcher whose work includes composition, improvisation, interactive system design and cross-disciplinary collaboration. His writings can be found in Organised Sound and Leonardo Music Journal among other publications, and his music is documented on Deep Listening, Pogus and other labels.

Pauline Oliveros: (1932) is a composer and improviser, teaches at RPI, plays a Roland V Accordion in solo and ensemble improvisations. Her works are available through download, cassette, CD, DVD, and Vinyl releases. Oliveros founded the Deep Listening Institute, Ltd. based in Kingston NY.

Jonas Braasch: Experimental soprano saxophonist and acoustician with interests in Telematic Music and Intelligent Music Systems. He has performed with Curtis Bahn, Chris Chafe, Michael Century, Mark Dresser, Pauline Oliveros, Doug van Nort and Stuart Dempster -- among others. He currently directs the Communication Acoustics and Aural Architecture Research Laboratory at RPI.},
  url       = {https://vimeo.com/27691551},
}

@InProceedings{nime2011-music-Schorno2011,
  author    = {Daniel Schorno and Haraldur Karlsson},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  title     = {7-of-12 dialectologies},
  year      = {2011},
  address   = {Oslo, Norway},
  editor    = {Kjell Tore Innervik and Ivar Frounberg},
  month     = jun,
  publisher = {Norwegian Academy of Music},
  abstract  = {Program notes: The formalistic identity of ``7-of-12'' consists of a showcase format for ``penta digit instrumental inventions'' diffused in quadrophonic audio and 3d interactive video projection. The dialectic intertwining of Karlsson's abstract art and Schorno's sonetic world extends into a composition of 12'' duration. Eponymous instrument group ``EIG''' consist of two former classmates of Sonology where they among other things studied the making of alternative electronic instruments. The performance``7-of-12 dialectologies'' is an outcome of collaborated teachings and methodology in dialogue with past performances.

About the performers: Daniel Schorno: composer, born in Zurich in 1963. Studied composition in London with Melanie Daiken and electronic and computer music in The Hague, with Joel Ryan and Clarence Barlow. Invited by Michel Waisvisz he led STEIM - the re-nown Dutch Studio for Electro Instrumental Music, and home of ``New Instruments'' - as Artistic Director until 2005. He is currently STEIM's composer-in-research and creative project advisor.
Haraldur Karlsson: visual artist, born in Reykjavik 1967. Haraldur studied Multi-media in the art academy in Iceland, Media-art in AKI in Enschede and Sonology in the Royal conservatories The Hague. Haraldur is mainly focused on interactive audio/video/3D installations and performances, and instrumental computer controllers. His fire instrument ``TFI''' is part of the Little Solarsystem ``LSS'' navigation system that is an audio/video/3D performance.},
  url       = {https://vimeo.com/27694220},
}

@InProceedings{nime2011-music-Dahl2011,
  author    = {Luke Dahl and Carr Wilkerson},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  title     = {TweetDreams},
  year      = {2011},
  address   = {Oslo, Norway},
  editor    = {Kjell Tore Innervik and Ivar Frounberg},
  month     = jun,
  publisher = {Norwegian Academy of Music},
  abstract  = {Program notes: TweetDreams uses real-time Twitter data to generate music and visuals. During the performance tweets containing specific search terms are retrieved from Twitter. Each tweet is displayed and plays a short melody. Tweets are grouped into trees of related tweets, which are given similar melodies. We invite the audience to participate in TweetDreams by tweeting during performance with the term \emph{\#Nime2011}. This term is used to identify tweets from the audience and performers. Global search terms are used to bring the world into the performance. Any tweet with these terms occurring anywhere in the world becomes part of the piece.

About the performers: Luke Dahl: Musician and engineer currently pursuing a PhD at Stanford University's CCRMA. His research interests include new musical instruments and performance ensembles, musical gesture, rhythm perception, and MIR. He has composed works for the Stanford Laptop and Mobile Phone Orchestras and also creates electronic dance music.
Carr Wilkerson: System Administrator at CCRMA specializing in Linux and Mac OS systems. He is a controller and software system builder and sometime performer/impresario, instructor and researcher.},
  url       = {https://vimeo.com/27694232},
}

@Comment{jabref-meta: databaseType:bibtex;}
@InCollection{nime2012-music-SchneiderbangerVierling2012,
  author    = {Matthias Schneiderbanger and Michael Vierling},
  booktitle = {NIME'12 Program},
  title     = {Floating Points II},
  year      = {2012},
  address   = {Ann Arbor, Michigan, U.S.A.},
  editor    = {Georg Essl and Brent Gillespie and Michael Gurevich and Sile O'Modhrain},
  month     = {May},
  day       = {21-23},
  publisher = {Electrical Engineering \& Computer Science and Performing Arts Technology, University of Michigan},
  note      = {Program notes:

The piece \emph{Floating Points II} is the result of the continued work of the instrument makers and performers Michael Vierling and Matthias Schneiderbanger within their self-developed system for collaborative performance including the digital musical instruments Sensor-table and Chirotron. These instruments use several sensors to transform the movements and gestures of their players into data for sound generation, placement and movement of the sound in the room.

The performances with \emph{Sensor-table} and \emph{Chirotron} emphasize the connection between the performer and the digital musical instruments by using the basic noise of the sensors as a notable characteristic in the sound synthesis to accentuate the technical boundaries in an aesthetic way. The network is the core of the common setup: It offers the ability to connect two physically separated instruments into one common signal chain for sound processing and spatialisation.

Composer(s) Credits:

Instrumentalist(s) Credits:

Matthias Schneiderbanger (Chirotron), Michael Vierling (Sensor-table)

Artist(s) Biography:

Matthias Schneiderbanger (*1987) musician and sonic artist, studies since 2007 at the Karlsruhe University of Music, Germany. Currently master student in music informatics with emphasis in composition and sonic arts. Main foucs on development of digital musical instruments, sound installations, contemporary music and live coding. Since 2010, there is also an artistic collaboration with M. Vierling in the development of digital musical instruments. Their instruments were presented 2011 at the Music and Sonic Arts Symposium in Baden-Baden, performances include the Network Music Festival in Birmingham and the ZKM in Karlsruhe. He is a member of the laptop ensemble Beno\^{i}t and the Mandelbrots, performances along with numerous other concerts at the BEAM Festival in Uxbridge, the SuperCollider Symposium 2012 in London, the Laptops Meet Musicians Festival 2011 in Venice and the next\- -generation 4.0 Festival at the ZKM in Karlsruhe. He is a member of Karlsruhe artist collective nil.

Michael Vierling studies music informatics master at the Karlsruhe University of Music, Germany. He is drummer in several band projects and teaches a drumclass at School for Music and Performing Arts in B\"{u}hl, Germany. His main interests besides producing and performing music are sonic arts especially live- electronics, creating digital music instruments and sound installations with use of sensor technologies. Since 2010, there is an artistic collaboration with M. Schneiderbanger in the development of digital musical instruments. Their instruments were presented 2011 at the Music and Sonic Arts Symposium in Baden-Baden, performances include, the NIME 2012 in Michigan and the Network Music Festival 2012 in Birmingham. His works have been exhibited at various Festivals e.g. ton:art 2010/11, UND 6/7, Sommerloch 2011, Beyond 3D-Festival in Karlsruhe and the Next Level Conference in Cologne. He is a member of Karlsruhe artist collective nil.

Concert Venue and Time: Lydia Mendelssohn Theatre, Monday May 21, 9:00pm
},
}

@InCollection{nime2012-music-HelmuthDanard2012,
  author    = {Mara Helmuth and Rebecca Danard},
  booktitle = {NIME'12 Program},
  title     = {Water Birds},
  year      = {2012},
  address   = {Ann Arbor, Michigan, U.S.A.},
  editor    = {Georg Essl and Brent Gillespie and Michael Gurevich and Sile O'Modhrain},
  month     = {May},
  day       = {21-23},
  publisher = {Electrical Engineering \& Computer Science and Performing Arts Technology, University of Michigan},
  note      = {Program notes:

Water Birds is an interactive and collaborative composition for clarinet, bass clarinet and computer. The sound of the clarinets is processed live by spectral delays with MaxMSP and rtcmix~. Space structures the composition, as the particular sound parameters initiated depend on the performer's location on the stage. The development of the current version of the piece involved a custom wireless infrared sensor network, which responds to the clarinetist's movements. Currently the piece is performed without the sensor network, but the strategy of that configuration still drives the composition. A score containing five sound-generating ideas, consisting of musical fragments and a Zen poem, allows the performer to improvise, creating his/her own sound pathway through the piece. The pathway is reminiscent of the path of birds in the Zen poem, Dogen's \emph{On the Nondependence of Mind}, which reads: ``Water birds/going and coming/their traces disappear/but they never/forget their path.''

Composer(s) Credits:

Mara Helmuth and Rebecca Danard

Instrumentalist(s) Credits:

Rebecca Danard (B$\flat$ Clarinet, bass clarinet), Mara Helmuth (Computer)

Artist(s) Biography:

Mara Helmuth composes music often involving the computer, and creates multimedia and software for composition and improvisation. Her recordings include Sounding Out! (Everglade, forthcoming 2010), Sound Collaborations, (CDCM v.36, Centaur CRC 2903), Implements of Actuation (Electronic Music Foundation EMF 023), and Open Space CD 16, and her work has been performed internationally. She is on the faculty of the College-Conservatory of Music, University of Cincinnati and its Center for Computer Music's director. She holds a D.M.A. from Columbia University, and earlier degrees from the University of Illinois, Urbana-Champaign. Her software for composition and improvisation has involved granular synthesis, Internet2, and RTcmix instruments. Her writings have appeared in \emph{Audible Traces, Analytical Methods of Electroacoustic Music, the Journal of New Music Research and Perspectives of New Music}. Installations including \emph{Hidden Mountain} (2007) were created for the Sino-Nordic Arts Space in Beijing. She is a past president of the International Computer Music Association.

Rebecca Danard: Performer, educator, scholar and entrepreneur, \textbf{Rebecca Danard} holds a doctorate in clarinet performance at the University of Cincinnati College-Conservatory of Music. Also an enthusiastic teacher, Rebecca is Adjunct Faculty at Carleton University. She is currently Artistic Director of the Ottawa New Music Creators: a collective of professional composers and performers dedicated to bringing contemporary music to Canada's capital. Rebecca's performance career centres on new and experimental music, including interdisciplinary collaborations, working with new technology, organizing events, and commissioning composers. She has worked with film makers, dancers, choreographers, actors, poets, lighting designers and visuals artists as well as performing musicians and composers. She has been invited to perform at festival such as Music10 (Hindemith Centre, Switzerland), the Ottawa Chamber Music Festival, the Ottawa Jazz Festival, the Bang on a Can Summer Festival, and Opera Theatre and Music Festival of Lucca; at conferences such as Clarinetfest, CLIEC and SEAMUS.

Concert Venue and Time: Lydia Mendelssohn Theatre, Monday May 21, 9:00pm
},
}

@InCollection{nime2012-music-TanakaParkinson2012,
  author    = {Atau Tanaka and Adam Parkinson},
  booktitle = {NIME'12 Program},
  title     = {4 Hands iPhone},
  year      = {2012},
  address   = {Ann Arbor, Michigan, U.S.A.},
  editor    = {Georg Essl and Brent Gillespie and Michael Gurevich and Sile O'Modhrain},
  month     = {May},
  day       = {21-23},
  publisher = {Electrical Engineering \& Computer Science and Performing Arts Technology, University of Michigan},
  note      = {Program notes:

Adam \& Atau exploit a commonly available consumer electronics device, a smartphone, as an expressive, gestural musical instrument. The device is well known an iconic object of desire in our society of consumption, playing music as a fixed commodity. The performers re-appropriate the mobile phone and transform the consumer object into an instrument for concert performance. As a duo, with one in each hand, they create a chamber music, 4-hands iPhone. The accelerometers allow high precision capture of the performer's free space gestures. This drives a granular synthesis patch in Pure Data (PD), where one patch becomes the process by which a range of sounds from the natural world are stretched, frozen, scattered, and restitched. The fact that all system components---sensor input, signal processing and sound synthesis, and audio output, are embodied in a single device make it a self-contained, expressive musical instrument.

Composer(s) Credits:

Atau Tanaka and Adam Parkinson

Instrumentalist(s) Credits:

Artist(s) Biography:

Atau Tanaka's first inspirations came upon meeting John Cage during his Norton Lectures at Harvard and would go to on re-create Cage's Variations VII with Matt Wand and \emph{:zoviet*france:}, performing it in Newcastle upon Tyne, Berlin, and Paris. In the 90's he formed Sensorband with Zbigniew Karkowski and Edwin van der Heide and then moved to Japan and came in contact with the noise music scene, playing with Merzbow, Otomo, KK Null and others. Atau has released solo, group, and compilation CD's on labels such as Sub Rosa, Bip-hop, Caipirinha Music, Touch/Ash, Sonoris, Sirr-ecords. His work has been presented at ICC in Japan, Ars Electronica, DEAF/V2, IRCAM, and Transmediale in Europe, and Eyebeam, Wood Street Gallery, and SFMOMA in the U.S. He has been artistic ambassador for Apple, researcher for Sony CSL, artistic co-director of STEIM, and director of Culture Lab Newcastle. He is currently European Research Council (ERC) fellow at Goldsmiths Digital Studios in London.

Adam Parkinson is an electronic musician based in Newcastle, England. He has recently completed PhD, with much of his research looking at mobile music and performing with iPhones.He has worked alongside various improvisers such as Rhodri Davies, Klaus Filip, Robin Hayward and Dominic Lash, and has been involved in collaborations to create sound installations with Kaffe Matthews and Caroline Bergvall. He also dabbles in making dance music, and is trying to write a perfect pop song.
Atau \& Adam have been performing as a duo since 2008: first as a laptop / biomuse duo then in the current iPhone formation. 4-Hands iPhone has so far been performed across Europe and North America including the FutureEverything Festival (Manchester), Passos Manuel (Porto), Charm of Sound Festival (Helsinki), Electron Festival (Geneva), Mois Multi (Quebec), Music With A View (New York).

Concert Venue and Time: Lydia Mendelssohn Theatre, Monday May 21, 9:00pm
},
}

@InCollection{nime2012-music-Applebaum2012,
  author    = {Mark Applebaum},
  booktitle = {NIME'12 Program},
  title     = {Aphasia},
  year      = {2012},
  address   = {Ann Arbor, Michigan, U.S.A.},
  editor    = {Georg Essl and Brent Gillespie and Michael Gurevich and Sile O'Modhrain},
  month     = {May},
  day       = {21-23},
  publisher = {Electrical Engineering \& Computer Science and Performing Arts Technology, University of Michigan},
  note      = {Program notes:

\emph{Aphasia} (2010), for solo performer and two-channel tape, was commissioned by the GRM, Paris and composed for virtuoso singer Nicholas Isherwood. The tape, an idiosyncratic explosion of warped and mangled sounds, is made up exclusively of vocal samples---all provided by Isherwood and subsequently transformed digitally.  Against the backdrop of this audio narrative, an elaborate set of hand gestures are performed---an assiduously choreographed sign language of sorts.  Each gesture is fastidiously synchronized to the tape in tight rhythmic coordination.

In the context of NIME, the piece is noteworthy for its deliberate---if unintentionally political---contemporary technology abstinence.  Ancillary questions arise, such as ``What are the present limits of gesture control?''; ``Do these limitations present unwelcome pressures on the boundaries of artistic imagination and creative capacity?''; and ``How do we learn to recognize when it is artistically prudent to eschew emerging tools?''

Composer(s) Credits:

Mark Applebaum

Instrumentalist(s) Credits:

Mark Applebaum

Artist(s) Biography:

Mark Applebaum is Associate Professor of Composition at Stanford University where he received the 2003 Walter J. Gores Award for excellence in teaching.  He received his Ph.D. in composition from the University of California at San Diego where he studied principally with Brian Ferneyhough.  His solo, chamber, choral, orchestral, operatic, and electroacoustic work has been performed throughout the United States, Europe, Africa, South America, and Asia.  Many of his recent works are characterized by challenges to the conventional boundaries of musical ontology.

Concert Venue and Time: Lydia Mendelssohn Theatre, Monday May 21, 9:00pm
},
}

@InCollection{nime2012-music-LeeuwSchwarz2012,
  author    = {Hans Leeuw and Diemo Schwarz},
  booktitle = {NIME'12 Program},
  title     = {Violent Dreams},
  year      = {2012},
  address   = {Ann Arbor, Michigan, U.S.A.},
  editor    = {Georg Essl and Brent Gillespie and Michael Gurevich and Sile O'Modhrain},
  month     = {May},
  day       = {21-23},
  publisher = {Electrical Engineering \& Computer Science and Performing Arts Technology, University of Michigan},
  note      = {Program notes:

Two typical NIME related inventions meet in this performance. IRCAM based Diemo Schwarz and HKU lecturer and Electrumpet player Hans Leeuw met at STEIM in 2010. The extreme sound possibilities of the sensor driven Electrumpet combine wonderfully with the corpus based techniques in CataRT. Both Diemo and Hans play their self-invented instruments for a number of years in which they have done several iterations / extensions and built a lot of performance experience. This experience pays off in the expressive capabilities of both performers making this a concert that goes far beyond an extended demonstration of new instruments. In \emph{Violent Dreams}, Hans's manipulated sounds are recorded in CataRT, from which Diemo chooses specific sonic characters and evolutions via gestural controllers, that are played back and transformed by CataRT, challenging Hans to come up with more extreme sounds surpassing his own originals. Thus we get an interesting and challenging improvisation battle between two players that both fully master their instrument.
Composer(s) Credits:

Instrumentalist(s) Credits:

Hans Leeuw (Electrumpet), Diemo Schwarz (CataRT, gestural controllers)

Artist(s) Biography:

Hans Leeuw is recognized as one of Hollands top players composers and bandleaders in the Jazz and improvised music scene even before he started to use electronics and designed his own Electrumpet. He is most noted as the bandleader of the Dutch formation Tetzepi, a 14 piece Big Band. Tetzepi exists for 15 years and is structurally funded by Dutch government.
Next to his activities as a performer Hans teaches at the Utrecht school for the arts at the Music Technology department and at the faculty Industrial Design of the Technical University Eindhoven where he coaches projects on the design of new musical instruments.
In 2008 he designed the Electrumpet, a hybrid electroacoustic instrument that differs from similar design in that it takes the trumpet players normal playing position and expression in account thus creating an instrument that combines acoustic and electronic expression seamlessly. (see `the electrumpet, additions and revisions')

Diemo Schwarz is a researcher and developer at Ircam, composer of electronic music, and musician on drums and laptop.  He holds a PhD in computer science applied to music for his research on corpus-based concatenative musical sound synthesis.
His compositions and live performances, under the name of his solo project Mean Time Between Failure, or improvising with musicians such as Fr\'{e}d\'{e}ric Blondy, Victoria Johnson, Pierre Alexandre Tremblay, Etienne Brunet, Luka Juhart, George Lewis, Evan Parker, explore the possibilities of corpus-based concatenative synthesis to re-contextualise any sound source by rearranging sound units into a new musical framework using interactive navigation through a sound space, controlled by gestural input devices.
His research work includes improving interaction between musician and computer, and exploiting large masses of sound for interactive real-time sound synthesis, collaborating with composers such as Philippe Manoury, Dai Fujikura, Stefano Gervasoni, Aaron Einbond, Sam Britton.

Concert Venue and Time: Lydia Mendelssohn Theatre, Monday May 21, 9:00pm
},
}

@InCollection{nime2012-music-PattonRovan2012,
  author    = {Kevin Patton and Butch Rovan},
  booktitle = {NIME'12 Program},
  title     = {the ellipsis catalog},
  year      = {2012},
  address   = {Ann Arbor, Michigan, U.S.A.},
  editor    = {Georg Essl and Brent Gillespie and Michael Gurevich and Sile O'Modhrain},
  month     = {May},
  day       = {21-23},
  publisher = {Electrical Engineering \& Computer Science and Performing Arts Technology, University of Michigan},
  note      = {Program notes:

\emph{the ellipsis catalog} features new instruments designed by Kevin Patton and Butch Rovan. Patton's instrument, the ``Fossil'', is a wireless sensor-based musical instrument that is played with the entire gestural range of arm movement as well as finger pressure. Four FSRs, a momentary button, and a two-dimensional accelerometer are used to control the parameters of a custom software environment built in Max/MSP/Jitter. It is part of a group of four hand-carved wood instruments called the Digital Poplar Consort.

Rovan's ``Banshee'' is an analog electronic musical instrument. Modeled after a wind instrument, the design uses six finger pads to control the pitch of an array of interrelated oscillators, and a mouth sensor that allows the performer to control volume. The Banshee also features a tilt-sensor that allows motion to change the voicing circuitry and resulting timbre. Battery powered, the instrument can plug into any amplifier or mixing console, much like an electric guitar.
Composer(s) Credits:

Instrumentalist(s) Credits:

Kevin Patton (Fossil), Butch Rovan (Banshee)

Artist(s) Biography:

Kevin Patton is a musician, scholar, and technologist active in the fields of experimental music and multimedia theatre whose work explores the intersection of technology and performance. The design of new musical instruments as well as interfaces and computer systems for analysis, improvisation, installation and projection is at the center of his practice. His work has been recognized for his collaboration with visual artist Maria del Carmen Montoya with the 2009 Rhizome commission for the piece, \emph{I Sky You}. Patton is an assistant professor of music and performance technologies at Oregon State University. He holds a Ph.D. and M.A. from Brown University in electronic music and multimedia composition. He also holds a Master of Music degree in jazz studies and composition from the University of North Texas. He was an Invited Researcher at the Sorbonne, University of Paris IV, for the Spring of 2009.

Butch Rovan is a media artist and performer at Brown University, where he co-directs MEME (Multimedia \& Electronic Music Experiments @ Brown). Rovan has received prizes from the Bourges International Electroacoustic Music Competition, the Berlin Transmediale International Media Arts Festival, and his work has appeared throughout Europe and the U.S. Most recently his interactive installation Let us imagine a straight line was featured in the 14th WRO International Media Art Biennale, Poland.
Rovan's research includes new sensor hardware design and wireless microcontroller systems. His research into gestural control and interactivity has been featured in IRCAM's journal Resonance, Electronic Musician, the \emph{Computer Music Journal}, the Japanese magazine \emph{SoundArts}, the CDROM \emph{Trends in Gestural Control of Music} (IRCAM 2000), and in the book \emph{Mapping Landscapes for Performance as Research: Scholarly Acts and Creative Cartographies} (Palgrave Macmillan, 2009).

Concert Venue and Time: Lydia Mendelssohn Theatre, Monday May 21, 9:00pm
},
}

@InCollection{nime2012-music-Marier2012,
  author    = {Martin Marier},
  booktitle = {NIME'12 Program},
  title     = {Clarinet (Albino Butterfly)},
  year      = {2012},
  address   = {Ann Arbor, Michigan, U.S.A.},
  editor    = {Georg Essl and Brent Gillespie and Michael Gurevich and Sile O'Modhrain},
  month     = {May},
  day       = {21-23},
  publisher = {Electrical Engineering \& Computer Science and Performing Arts Technology, University of Michigan},
  note      = {Program notes:

\emph{Clarinet} is the third piece in a series of monotimbral works.  Like its siblings \emph{Piano} and \emph{Cymbal}, it was inspired by the sound qualities of an acoustic instrument. This minimalist and meditative piece is a structured improvisation performed on the sponge, a musical interface designed by the composer. The sponge is basically a cushion equipped with sensors (accelerometers, buttons and force sensing resistors) which detect when it is squeezed, twisted or shaken.  Because the sponge evolves continuously, the piece exists in many versions.  Each new version drifts further away from the original compositional intentions and the piece is slowly becoming less meditative.  The latest version is subtitled Albino Butterfly.

Composer(s) Credits:

Martin Marier

Instrumentalist(s) Credits:

Martin Marier (Sponge)

Artist(s) Biography:

Martin Marier is a composer and a performer who is mainly interested in live electronic music using new interfaces.  He is the inventor of the sponge, a cushion like musical interface that he uses to perform his pieces.  The main goal of this approach is to establish a natural link between gesture and sound in electronic music.  He aims at improving the interaction with the audience and at making the process of composing more playful.  His research on the sponge is the topic of the doctorate he is pursuing at the Universit de Montral under the supervision of Prof. Jean Pich\'{e}.  He was also supervised by Dr. Garth Paine during an exchange at the University of Western Sydney (Australia) in 2011.
Martin has also composed music for theatre, collaborating mostly with the Th\'{e}\^{a}tre I.N.K. company for whom he wrote the music of three plays: "L'effet du temps sur Mat\'{e}vina" (2012), "Roche, papier... couteau" (2007), "La cadette" (2006).  He sometimes writes music for films and collaborates with the film composer Benoit Charest. He is one of the founders of Point d'\'{e}coute (PDE), a collective whose purpose is to promote electroacoustic music.  Along with his four colleagues of PDE, he produced concerts in Montreal, New York and Sydney.

Concert Venue and Time: Lydia Mendelssohn Theatre, Monday May 21, 9:00pm
},
}

@InCollection{nime2012-music-OuzounianKnappLyonDuBois2012,
  author    = {Gascia Ouzounian and R.~Benjamin Knapp and Eric Lyon and R.~Luke DuBois},
  booktitle = {NIME'12 Program},
  title     = {Music for Sleeping \& Waking Minds},
  year      = {2012},
  address   = {Ann Arbor, Michigan, U.S.A.},
  editor    = {Georg Essl and Brent Gillespie and Michael Gurevich and Sile O'Modhrain},
  month     = {May},
  day       = {21-23},
  publisher = {Electrical Engineering \& Computer Science and Performing Arts Technology, University of Michigan},
  note      = {Program notes:

\emph{Music for Sleeping \& Waking Minds} (2011-2012) is an overnight event in which four performers fall asleep while wearing custom designed EEG sensors, which monitor their brainwave activity over the course of one night. The data gathered from the EEG sensors is applied in real time to different audio and image signal processing functions, resulting in a continuously evolving multi-channel sound environment and visual projection. This material serves as an audiovisual description of the individual and collective neurophysiological state of the ensemble, with sounds and images evolving according to changes in brainwave activity. Audiences, who are invited to bring anything that they need to ensure comfortable sleep, can experience the work in different states of attention: while alert and sleeping, resting and awakening.

Gascia Ouzounian (composition \& production), R. Benjamin Knapp (physiological interface \& interaction design), Eric Lyon (audio interface \& interaction design),  R. Luke DuBois (visual interface \& interaction design)Composer(s) Credits:

Gascia Ouzounian (composition \& production), R. Benjamin Knapp (physiological interface \& interaction design), Eric Lyon (audio interface \& interaction design),  R. Luke DuBois (visual interface \& interaction design)

Instrumentalist(s) Credits:

Artist(s) Biography:

Gascia Ouzounian is a violinist, musicologist, and composer. She has performed with such varied ensembles as Yo-Yo Ma and the Silk Road Ensemble at Carnegie Hall, Bang On A Can All-Stars at the Mass MOCA, Sinfonia Toronto at the Toronto Centre for the Arts, and the Theatre of Eternal Music Strings Ensemble at the Dream House. Gascia's recent projects include two compositions that are intended for overnight listening: EDEN EDEN EDEN with filmmaker Chloe Griffin, and \emph{Music for Sleeping \& Waking Minds} with R. Benjamin Knapp, Eric Lyon and R. Luke DuBois. In the latter, an ensemble of sleeping performers generates an audiovisual environment through their neurophysiological activity over the course of one night. Gascia teaches at Queen's University Belfast, where she leads the performance programme in the School of Creative Arts. Her writings on experimental music and sound art appear in numerous academic journals and the book \emph{Paul DeMarinis: Buried in Noise.}

R. Benjamin Knapp is the founding director of the Institute for Creativity, Arts, and Technology at Virginia Tech, where he is Professor of Computer Science. Ben has led the Music, Sensors and Emotion (MuSE) group, whose research focuses on the understanding and measurement of the physical gestures and emotional states of musical performers and their audience. For over 20 years, Ben has been researching and developing user-interfaces and software that enable composers and performers to augment the physical control of a musical instrument with more direct neural interaction. From the invention of the Biomuse with Hugh Lusted in 1987 to the introduction of the concept of an Integral Music Controller (a generic class of controllers that use the direct measurement of motion and emotion to augment traditional methods of musical instrument control) in 2005, Ben has focused on creating a user-aware interface based on the acquisition and real-time analysis of biometric signals.

Eric Lyon is a composer and computer music researcher. During the 1980s and 1990s, his fixed media computer music focused on spectral and algorithmic processing of audio, with a tendency toward extreme modifications of samples, variously sourced. From the early 1990s, Lyon became involved with live computer music, performing solo, and in the Japanese band Psychedelic Bumpo, with the Kyma system. Later in the 1990s, he gravitated toward software-based live processing, starting to develop Max/MSP externals in 1999. This work resulted in his LyonPotpourri collection of Max/MSP externals, and the FFTease spectral package, developed in collaboration with Christopher Penrose. In recent years, Lyon has focused on computer chamber music, which integrates live, iterative DSP strategies into the creation of traditionally notated instrumental scores. Other interests include spatial orchestration, and articulated noise composition. Lyon teaches computer music in the School of Music and Sonic Art at Queen's University Belfast.

R. Luke DuBois is a composer, artist, and performer who explores the temporal, verbal, and visual structures of cultural and personal ephemera. He has collaborated on interactive performance, installation, and music production work with many artists and organizations including Toni Dove, Matthew Ritchie, Todd Reynolds, Jamie Jewett, Bora Yoon, Michael Joaquin Grey, Elliott Sharp, Michael Gordon, Maya Lin, Bang on a Can, Engine27, Harvestworks, and LEMUR, and was the director of the Princeton Laptop Orchestra for its 2007 season. Stemming from his investigations of ``time-lapse phonography,'' his recent work is a sonic and encyclopedic relative to time-lapse photography. Just as a long camera exposure fuses motion into a single image, his work reveals the average sonority, visual language, and vocabulary in music, film, text, or cultural information. He teaches at the Brooklyn Experimental Media Center at the Polytechnic Institute of NYU, and is on the Board of Directors of Issue Project Room.

Concert Venue and Time: North Quad Space 2435, Monday May 21, 11:00pm
},
}

@InCollection{nime2012-music-Bloland2012,
  author    = {Per Bloland},
  booktitle = {NIME'12 Program},
  title     = {Of Dust and Sand},
  year      = {2012},
  address   = {Ann Arbor, Michigan, U.S.A.},
  editor    = {Georg Essl and Brent Gillespie and Michael Gurevich and Sile O'Modhrain},
  month     = {May},
  day       = {21-23},
  publisher = {Electrical Engineering \& Computer Science and Performing Arts Technology, University of Michigan},
  note      = {Program notes:

\emph{Of Dust and Sand} uses the Electromagnetically-Prepared Piano device, a rack of 12 electromagnets which is suspended over the strings of a piano. Each electromagnet is sent an audio signal and in turn excites its respective string, much like a stereo speaker made from piano strings. In this piece a subset of the magnets remains active throughout, the performer physically silencing the strings by pressing down with fingertips. Thus the instrument becomes a kind of anti-piano---lifting a finger frees a string to vibrate, producing sound. In addition, various items, such as paper and a plastic ruler, rest directly on the strings further altering the timbre. Remember---everything you hear is entirely acoustic.

Of Dust and Sand is dedicated to The Kenners.

Composer(s) Credits:

Per Bloland

Instrumentalist(s) Credits:

Daniel Graser (alto saxophone), Veena Kulkarni (piano)

Artist(s) Biography:

Per Bloland is a composer of acoustic and electroacoustic music whose works have been described as having an ``incandescent effect''  with ``dangerous and luscious textures.''  His compositions range from short intimate solo pieces to works for large orchestra, and incorporate video, dance, and custom built electronics. He has received awards and recognition from organizations such as SEAMUS/ASCAP, Digital Art Awards of Tokyo, ISCM, and SCI/ASCAP. He is currently a Visiting Assistant Professor of Computer Music at the Oberlin College Conservatory, and serves as the founding director of OINC, the Oberlin Improvisation and Newmusic Collective.
For more information, please see: www.perbloland.com.

Daniel Graser: Saxophonist \textbf{Daniel Graser} is emerging as one of the most innovative performers and pedagogues of his generation. A recent recipient of the Doctorate of Musical Arts from the University of Michigan, Dan served as Teaching Assistant to legendary saxophone pedagogue Donald Sinta for the past three years and joined the faculty of Oakland University School of Music, Theater, and Dance in 2011. Previously, Dan earned a Masters Degree from the University of Michigan in 2008 and Bachelors degrees in music theory/history and saxophone performance as a student of Dr. Timothy McAllister at the Crane School of Music in 2007. As an orchestral performer, Dan has performed as principal saxophonist with the National Wind Ensemble in Carnegie Hall under H. Robert Reynolds, the Detroit Symphony Orchestra under Leonard Slatkin, The New World Symphony under Michael Tilson Thomas and John Adams, the Ann Arbor Symphony under Arie Lipsky, the University of Michigan Symphony Orchestra under Kenneth Kiesler, the Hot Springs Festival Orchestra under Richard Rosenberg, and the Orchestra of Northern New York under Kenneth Andrews. Dan was selected by the University of Michigan to be featured as a recitalist at the Kennedy Center for the Performing Arts in Washington DC as part of the Millenium Stage Series. Recent and forthcoming performances include world premieres at the University of Michigan, orchestral performances with the New World Symphony and the Detroit Symphony Orchestra as well as chamber music performances at the Navy Band International Saxophone Symposium and the 2012 North American Saxophone Association Biennial Conference

Veena Kulkarni: A regular performer in southeast Michigan, \textbf{Veena Kulkarni} teaches at the Faber Piano Institute and Madonna University.  Veena's performances have taken her throughout the United States and beyond as both a soloist and collaborator.  In October, Veena won Best Liszt Interpretation in the 2011 Liszt-Garrison International Piano Competition.
Veena is the pianist for Eero Trio, whose debut CD entitled Wolf Glen was released in 2010.  Wolf Glen features the premiere recording of Christopher Dietz's Fumeux fume, for clarinet, cello \& piano. Veena completed her doctorate in Piano Performance and Pedagogy under Logan Skelton and John Ellis at the University of Michigan.  Prior to that, she studied at Indiana University with Emile Naoumoff and Professors Brancart, Auer, Gulli and Tocco and at the Royal Academy of Music with Hamish Milne.

Concert Venue and Time: Lydia Mendelssohn Theatre, Tuesday May 22, 7:00pm
},
}

@InCollection{nime2012-music-Deal2012,
  author    = {Scott Deal},
  booktitle = {NIME'12 Program},
  title     = {Jack Walk},
  year      = {2012},
  address   = {Ann Arbor, Michigan, U.S.A.},
  editor    = {Georg Essl and Brent Gillespie and Michael Gurevich and Sile O'Modhrain},
  month     = {May},
  day       = {21-23},
  publisher = {Electrical Engineering \& Computer Science and Performing Arts Technology, University of Michigan},
  note      = {Program notes:

\emph{Jack Walk} explores notions of ecstatic energy, control and release. The work begins with live and fixed percussion lines, re-processed into a series of electronic representations of specified structure. This provides a compositional framework that a percussionist interacts with, while in another sonic layer, a laptop musician simultaneously samples and re-processes the live percussion while channeling the audio back into the larger environment. A videographer mixes imagery related to the original compositional notions of ecstatic control and release. Layers of sonic material emanating from the drummer's kit blur the virtual and real, while the music and imagery evoke imaginary lines tracing physical and conceptual flows of energy. The trio of performers for the NIME 2012 performance of \emph{Jack Walk} (Deal, Drews, and Munson) comprise group known as Big Robot, an Indianapolis-based computer-acoustic trio that creates live, interactive, and media-enriched works.

Composer(s) Credits:

Scott Deal

Instrumentalist(s) Credits:

Scott Deal (percussion), Michael Drews (audio electronics), Jordan Munson (video)

Artist(s) Biography:

Scott Deal has premiered solo, chamber and mixed media works throughout North America Europe, and Asia. An artist who ``displays phenomenal virtuosity'' (Artsfuse) and presents a ``riveting performance'' (Sequenza 21), his recording of John Luther Adams's \emph{Four Thousand Holes}, for piano, percussion, and electronics was listed in New Yorker Magazine's 2011 Top Ten Classical Recordings. In 2011, he and composer Matthew Burtner were awarded the Internet2 IDEA Award for their co-creation of \emph{Auksalaq}, a telematic opera.  Deal is Professor of Music and Director of the Donald Louis Tavel Arts and Technology Research Center at Indiana University Purdue University Indianapolis (IUPUI). He is the founder and director of the Telematic Collective, a multi-disciplinary artistic research group comprised of graduate students and professional collaborators. He also serves on the faculty for the Summer Institute for Contemporary Performance Practice at the New England Conservatory.

Michael Drews is a composer, sound artist and computer musician. His work explores unconventional narrative strategies created from transforming contextual identity and the expressive power of cultural artifacts found in particular sonic and visual materials. Present throughout Drews's work is an interest in performance-based computer virtuosity and improvisational applications of computer technology that expand traditional ideas of musical performance and creativity. Drews is a member of computer-acoustic ensemble, Big Robot and the experimental-electronica duo, Mana2. Performances of Drews's compositions have been featured at SEAMUS, Cinesonika, Electronic Music Midwest, NYC Electronic Music Festival, Studio 300, PASIC, Super Computing Global and IASPM-Canada. Drews holds degrees from the University of Illinois at Urbana-Champaign (D.M.A.), Cleveland State University (M.MUS.) and Kent State University (B.A.). He resides with his family in Indianapolis and is Assistant Professor of Music at Indiana University-Indianapolis (IUPUI). For more information: michaeldrews.org or Twitter.com/MICHAEL-DREWS

Jordan Munson is a musician, composer, and multimedia artist.  He is a Lecturer in Music and Arts Technology, and an associate of the Donald Louis Tavel Arts and Technology Research Center, both at Indiana University Purdue University Indianapolis (IUPUI).  His works for multimedia and music have been premiered at institutions such as the University of Kentucky, the University of Alaska at Fairbanks and the University of California San Diego. As a video artist, he has shown work at New York City Electro-Acoustic Music Festival and SEAMUS. Munson's experimental electronic efforts have resulted in performances alongside artists such as Matmos, R. Luke DuBois and Bora Yoon. He is a member of the computer-acoustic ensemble Big Robot, in which he work focuses on live experimental percussion and electronics. Munson holds degrees from Indiana University in Indianapolis (M.S.M.T.) and the University of Kentucky (B.M.).

Concert Venue and Time: Lydia Mendelssohn Theatre, Tuesday May 22, 7:00pm
},
}

@InCollection{nime2012-music-Morales-Manzanares2012,
  author    = {Roberto Morales-Manzanares},
  booktitle = {NIME'12 Program},
  title     = {Desamor I},
  year      = {2012},
  address   = {Ann Arbor, Michigan, U.S.A.},
  editor    = {Georg Essl and Brent Gillespie and Michael Gurevich and Sile O'Modhrain},
  month     = {May},
  day       = {21-23},
  publisher = {Electrical Engineering \& Computer Science and Performing Arts Technology, University of Michigan},
  note      = {Program notes:

\emph{Desamor I} is inspired in a model of meditation where primordial awareness or naturally occurring timeless awareness is seen as a result of a conversation with my wife Alejandra. This work is for piano, computer and two Wii controllers attached to my forearms. The output is 4 channels. The gestures of the pianist (movement, timber and dynamics) are captured in real time via 2 microphones and a set of 2 Wii controllers. The computer languages involved in the development of the project were: Escamol, a prolog environment for algorithmic composition designed by the composer, and SuperCollider. In this piece I share my experience as a performer-composer within a multi-platform programming environments involving signal processing and machine learning techniques.

Composer(s) Credits:

Roberto Morales-Manzanares

Instrumentalist(s) Credits:

Roberto Morales-Manzanares (piano, percussion and electronics)

Artist(s) Biography:

Roberto Morales-Manzanares: Born in Mexico City, \textbf{Roberto Morales-Manzanares} started his musical training in national folkloric music and learned how to play harps and different kinds of guitars and flutes from several regions of the country. His doctorate in music composition was completed at UC Berkeley in 2006. As a composer, he has written music for theater, dance, movies, TV and radio. As an interpreter Morales-Manzanares has participated on his own and with other composers in forums of jazz, popular and new music, including tours to Europe United States and Latin-America.
As a researcher, he has been invited to different national and international conferences such as ICMC, International Join Conference on Artificial Intelligence IJCAI and Symposium on Arts and Technology and has several publications. Currently he is member of the ``Sistema Nacional de Creadores''. His music can be found in ICMC recordings, Victo label www.victo.qc.ca (Leyendas in collaboration with Mari Kimura) and Irradia/Pocoscocodrilos.

Concert Venue and Time: Lydia Mendelssohn Theatre, Tuesday May 22, 7:00pm
},
}

@InCollection{nime2012-music-Hsu2012,
  author    = {Bill Hsu},
  booktitle = {NIME'12 Program},
  title     = {Flue},
  year      = {2012},
  address   = {Ann Arbor, Michigan, U.S.A.},
  editor    = {Georg Essl and Brent Gillespie and Michael Gurevich and Sile O'Modhrain},
  month     = {May},
  day       = {21-23},
  publisher = {Electrical Engineering \& Computer Science and Performing Arts Technology, University of Michigan},
  note      = {Program notes:

\emph{Flue} is a structured audio-visual improvisation for three musicians, utilizing live acoustic and electronic sound and interactive animations. A physics-based smoke simulation is influenced by the real-time audio from the musicians' performance. The audio from the performance is analyzed; high-level tempo, spectral and other features are extracted, and sent via Open Sound Control to the animation environment. The smoke trails are also able to coalesce into well- defined symbols and forms, all while moving in a natural-seeming manner consistent with the underlying fluid simulation.

Composer(s) Credits:

Bill Hsu

Instrumentalist(s) Credits:

Bill Hsu (electronics, interactive animation), Matt Endahl (piano), Mike Khoury (violin)

Artist(s) Biography:

Bill Hsu is an Associate Professor of Computer Science at San Francisco State University. He has performed in the US, Asia, and Europe, including NIME 2011 (Oslo), Festival art::archive:architectures (ZKM, Karlsruhe, 2011), SMC 2009 (Porto), Harvestworks Festival 2009 (New York), Fete Quaqua 2008 (London), MIX Festival 2007 and 2009 (New York), NIME 2007 (New York), Stimme+ 2006 (ZKM, Karlsruhe), and the First Hong Kong Improvised Performance Festival 2005. Website: http://userwww.sfsu.edu/~whsu/art.html

Matt Endahl (b. 1985) is an improvising pianist based in Ann Arbor, MI. A student of Geri Allen and Ed Sarath at the University of Michigan, Matt is an active performer and organizer, having performed in a wide variety of settings, from Gershwin's "Rhapsody in Blue" to freeform solo electronic sets. Matt has taught jazz piano at Hillsdale College since 2008. http://www.myspace.com/mattendahl

Mike Khoury was born in Mt. Pleasant, Michigan in 1969. As the son of visual artist Sari Khoury, he was exposed to various forms of visual arts and creative musical forms. Khoury is Palestinian.
Khoury's collaborators often include Leyya Tawil (dance), Ben Hall (percussion), Christopher Riggs (guitar), and Andrew Coltrane (sound manipulation). He has performed and recorded with Faruq Z. Bey, Dennis Gonzalez, Luc Houtkamp, Maury Coles, Jack Wright, Graveyards, John Butcher, Gino Robair, Gunda Gottschalk, and Le Quan Ninh.
Khoury runs the Entropy Stereo music label where he focuses on issuing new and archival music by challenging artists. His studies include those with John Lindberg, Gerald Cleaver, and composer/violinist David Litven. Khoury is the author of a chapter on Egyptian-American composer Halim El-Dabh in a forthcoming anthology on the Arab avant garde, published by Wesleyan University Press. Website: http://www.myspace.com/michaelkhoury

Concert Venue and Time: Lydia Mendelssohn Theatre, Tuesday May 22, 7:00pm
},
}

@InCollection{nime2012-music-GoloveMartensson2012,
  author    = {Jonathan Golove and Magnus Martensson},
  booktitle = {NIME'12 Program},
  title     = {Rachmaninoff-Wilson Medley},
  year      = {2012},
  address   = {Ann Arbor, Michigan, U.S.A.},
  editor    = {Georg Essl and Brent Gillespie and Michael Gurevich and Sile O'Modhrain},
  month     = {May},
  day       = {21-23},
  publisher = {Electrical Engineering \& Computer Science and Performing Arts Technology, University of Michigan},
  note      = {Program notes:

The most impressive uses of the theremin cello during Theremin's time in New York are Leopold Stokowski's inclusion of one in the Philadelphia Orchestra's low string section and Varese's composition of two solo parts in Ecuatorial.  Even more important, from my perspective, is the fact that the instrument represents the first attempt to harness the human potential to shape and manipulate electronic sound by means of the technical apparatus of the modern player of bowed string instruments.

Rachmaninoff's Vocalise, Op. 34 no. 14, for textless high voice, highlights the hauntingly vocal quality of the theremin cello. Vocalise is the last of a set of 14 songs published in 1912, less than a decade before Theremin's experiments with musical sounds began to bear fruit.

Brian Wilson and the Beach Boys, by virtue of their use of Bob Whitsell's Electro-Theremin on several recordings, are irrevocably linked to the history of the theremin.

Composer(s) Credits:

Vocalise, Op.34 no. 14  - \emph{Sergei Rachmaninoff}
Medley (Good Vibrations/God Only Knows) - \emph{Brian Wilson}

Instrumentalist(s) Credits:

Jonathan Golove (Theremin cello), Magnus Martensson (piano)

Artist(s) Biography:

Jonathan Golove, Associate Professor of Music at the University at Buffalo, has been featured as theremin cello soloist with the Asko/Schoenberg Ensemble, London Sinfonietta, and International Contemporary Ensemble; and as cello soloist with the Buffalo Philharmonic Orchestra, Slee Sinfonietta, and New York Virtuoso Singers. He has recorded for the Albany, Centaur, Albuzerque, and Nine Winds labels, and appeared at festivals including the Holland Festival, Festival d'Automne, Lincoln Center Festival, June in Buffalo, and the Festival del Centro Hist\'{o}rico (Mexico City). Golove gave the first performance of Varese's \emph{Ecuatorial} using Floyd Engel's recreation of the legendary early 20th century instrument at the University at Buffalo in 2002. He is also active as an electric cellist, particularly in the field of creative improvised music. An accomplished composer, his works have been performed at venues including the Kennedy Center, Venice Biennale, Festival of Aix-en-Provence, Lincoln Center Chamber Music Society II, and the Kitchen.

Magnus Martensson is Music Director of The Scandinavian Chamber Orchestra of New York; between 1996 and 2007 he was Visiting Assistant Professor at SUNY Buffalo and conductor of the Slee Sinfonietta. In 1989, Martensson made his operatic debut in Malm\''{o}, Sweden, conducting a production of Offenbach's Orpheus in the Underworld, and has subsequently conducted operas by Mozart, Puccini, Golove, among others.  He has conducted several world premiere recordings, including orchestral music by Jeffrey Stadelman, Roger Reynolds, and David Felder.
In the past few seasons Martensson has guest conducted with the New York New Music Ensemble, the Trondheim Soloists, Musica Vitae, ICE, and at the Monday Evening Concert Series (Los Angeles), The Manhattan School of Music, and Teatro San Martin (Buenos Aires).

Concert Venue and Time: Lydia Mendelssohn Theatre, Tuesday May 22, 7:00pm
},
}

@InCollection{nime2012-music-Alexander2012,
  author    = {Robert Alexander and David Biedenbender and Anton Pugh and Suby Raman and Amanda~Sari Perez and Sam~L. Richards},
  booktitle = {NIME'12 Program},
  title     = {Thought.Projection},
  year      = {2012},
  address   = {Ann Arbor, Michigan, U.S.A.},
  editor    = {Georg Essl and Brent Gillespie and Michael Gurevich and Sile O'Modhrain},
  month     = {May},
  day       = {21-23},
  publisher = {Electrical Engineering \& Computer Science and Performing Arts Technology, University of Michigan},
  note      = {Program notes:

The MiND Ensemble (Music in Neural Dimensions) is a new-media performance group that utilizes custom interfaces to explore the mind-machine-music connection. The traditional realization of the creative process ahs been as follows: there is an artist, a thought process, and a fixed medium which actualizes those thoughts. Neurofeedback radically shifts this paradigm. Now there is an artist and a dynamic medium that actively interfaces with the thought processes of the artist himself, drastically reshaping the way we understand the creative process. The MiND Ensemble promotes a rich awareness in which the mind is the creative medium. All projection and audio processing in this piece are driven in real time, with data gathered from the Emotiv EPOC headset.

Composer(s) Credits:

Robert Alexander, David Biedenbender, Anton Pugh, Suby Raman, Amanda   Sari Perez, Sam L. Richards

Instrumentalist(s) Credits:

Jeremy Crosmer (violoncello), Robert Alexander (MiND Synth / Emotiv), Anton Pugh (MiND Synth / Emotiv)

Artist(s) Biography:

Robert Alexander is a Sonification Specialist with the Solar Heliospheric Research group at the University of Michigan, where he is pursuing a PhD in Design Science. He was awarded a JPFP Fellowship from NASA, an Outstanding Achievement award from ICAD, and is an Artist in Residence with the Imagine Science Film Festival. He has collaborated with artists such as DJ Spooky, and performed on several international stages. He founded the MiND Ensemble in 2010.

David Biedenbender is currently a doctoral student in music composition at the University of Michigan. His first musical collaborations were in rock and jazz bands as an electric bassist and in jazz and wind bands as a bass trombonist and euphonium player. His present interests include working with everyone from classically trained musicians to improvisers, fixed electronics to brain data.

Anton Pugh is a Masters student in Electrical Engineering: Systems (Signal Processing concentration) at the University of Michigan. Presently he is working on expanding his knowledge of the Processing and iOS platforms, especially as they apply to the MiND Ensemble. His primary hobby is designing and building custom electronic instruments and new musical interfaces. He is also an active musician and plays viola in the Campus Symphony Orchestra.

Suby Raman is a composer, conductor, polyglot and linguist. His major artistic passion is drawn from language itself: the basic aural and mental components of language, how it determines, separates and unites cultures, and its influence (or lack thereof) on our perception and expression of reality. He has conducted research in brain-computer interface technology, which assist people afflicted by ALS and spinal cord injuries.

Amanda Sari Perez is a researcher with the Neural Engineering lab at the University of Michigan. She is currently working with microelectrode arrays to record brain activity from implanted sites. In 2009 she co- founded the Ann Arbor HackerSpace, a DIY community engaged in hands-on learning. For the past 3 years she has created artistic installations for the Burning Man festival, including a performance that deconstructs participants' notions of the self. Amanda is with the MiND Ensemble to work toward lowering the barrier for creative expression.

Sam L. Richards is a composer, artist, and researcher with a penchant for interdisciplinary collaboration and an appetite for creative engagement of unwieldy conceptual problems. As a composer he has worked with media artists, filmmakers, animators, and choreographers, as well as making music for the concert hall. Although formally trained as a musician, he also produces video installations, visual and aural media, creative writing, and regularly steps off the beaten path in order to engage new things in new ways.

Jeremy Crosmer is a gifted young professional cellist and composer. After achieving a double-major in music and mathematics from Hendrix College, he went on to receive multiple graduate degrees from the University of Michigan by the age of 23. As a cellist, Crosmer has performed across the country, soloing with orchestras in Arkansas and attending music festivals from Music Academy of the West to Tanglewood Music Center. An avid promoted of new music, Crosmer has both commissioned and premiered dozens of works by composers at Michigan and elsewhere. His performance dissertation at the University of Michigan is a study of the music of Paul Hindemith and cello sonatas by French composers during World War I.

Concert Venue and Time: Lydia Mendelssohn Theatre, Tuesday May 22, 7:00pm
},
}

@InCollection{nime2012-music-KimuraKato2012,
  author    = {Mari Kimura and Tomoyuki Kato},
  booktitle = {NIME'12 Program},
  title     = {Eigenspace},
  year      = {2012},
  address   = {Ann Arbor, Michigan, U.S.A.},
  editor    = {Georg Essl and Brent Gillespie and Michael Gurevich and Sile O'Modhrain},
  month     = {May},
  day       = {21-23},
  publisher = {Electrical Engineering \& Computer Science and Performing Arts Technology, University of Michigan},
  note      = {Program notes:

\emph{Eigenspace} (2011) is a collaborative project with Japan's leading visual artist in new media, Tomoyuki Kato (Movie Director), with Yoshito Onishi (Image Programing), and Chisako Hasegawa (Producer).  As Japanese, we were deeply touched by the Fukushima nuclear meltdown, the worst manmade catastrophe in the history of the human kind, which is not contained today contaminating the globe.  Eigenspace is about our love and prayer for the humankind and our planet, and for the next generation. The name is also taken from ``eigenvalue,'' a mathematical function used in analyzing the bowing movement, which interacts in real time with Mr. Kato's software.  The musical expression is extracted by IRCAM's ``Augmented Violin'' and their newest motion sensor ``mini-MO'', custom-fit into a glove designed by Mark Salinas. Special thanks to the Real Time Musical Interactive Team at IRCAM. Eigenspace was commissioned by Harvestworks, and premiered at Roulette in Brooklyn, on October 9th, 2011.

Composer(s) Credits:

Tomoyuki Kato (Movie Director), with Yoshito Onishi (Image Programing), and Chisako Hasegawa (Producer)

Instrumentalist(s) Credits:

Mari Kimura (violin), Tomoyuki Kato (Interactive graphics)

Artist(s) Biography:

Mari Kimura: Violinist/composer \textbf{Mari Kimura} is widely admired as the inventor of ``Subharmonics'' and her works for interactive computer music. As a composer, Mari's commissions include the International Computer Music Association, Harvestworks, Music from Japan, and received grants including NYFA, Arts International, Meet The Composer, Japan Foundation, Argosy Foundation, and NYSCA. In 2010 Mari won the Guggenheim Fellowship in Composition, and invited as Composer-in-Residence at IRCAM in Paris.   In October 2011, the Cassatt String Quartet premiered Mari's \emph{``I-Quadrifoglo''}, her string quartet with interactive computer at the Symphony Space in NYC, commissioned through Fromm Commission Award.  Feature articles in the past year include: the New York Times (May 13th, written by Matthew Gurewitsch), and Scientific American (May 31st, written by Larry Greenemeier). Mari's CD, \emph{The World Below G and Beyond}, features her Subharmonics works and interactive computer music.  Mari teaches a course in Interactive Computer Performance at Juilliard.  http://www.marikimura.com


Tomoyuki Kato is a renowned Japanese visual artist/movie director who works in a wide range of high-tech projects including advertisements, commercials, museums exhibitions and theme-parks.  Kato's work is known for the superb quality, high impact, originality and new technical methods.  Recently, Kato has been active in creating corporate future vision, such as ``concept car,'' incorporating live action, computer graphics and animation on project bases; his recent exhibition includes 2010 Shanghai Expo.  His highly acclaimed ``Grand Odyssey,'' created for 2005 Aichi Expo's Toshiba/Mitsui pavilion, is now displayed at Nagasaki's Huistenbosch theme-park. In 2010, Kato created ``Better Life from Japan,'' an exhibit for Otsuka Pharmaceutical company at Shanghai Expo, using a 360-degree display.  Kato has received and nominated for numerous awards at international and national festivals, including Japan Ministry of Culture Media Arts Festival, Los Angels International Short Film Festival, Montreal International Film Festival and London International Advertising Festival.

Concert Venue and Time: Lydia Mendelssohn Theatre, Tuesday May 22, 7:00pm
},
}

@InCollection{nime2012-music-KimYeo2012,
  author    = {Bongjun Kim and Woon Seung Yeo},
  booktitle = {NIME'12 Program},
  title     = {Where Are You Standing?},
  year      = {2012},
  address   = {Ann Arbor, Michigan, U.S.A.},
  editor    = {Georg Essl and Brent Gillespie and Michael Gurevich and Sile O'Modhrain},
  month     = {May},
  day       = {21-23},
  publisher = {Electrical Engineering \& Computer Science and Performing Arts Technology, University of Michigan},
  note      = {Program notes:

\emph{Where Are You Standing?} (2012) is a collaborative mobile music piece using the digital compass on mobile phones as an intuitive, interactive musical instrument. The piece features performers on stage making sound by aiming at other performers: compass-measured orientation of each aiming gesture is mapped to a specific musical note depending on which player is aimed at, and is visualized on screen in real-time.

The piece begins with three performers playing ``harmonic'' sounds by taking aim at each other. This consonance is broken by the introduction of the fourth performer who represents conflict: the notes played by this performer as well as the notes played by others when they aim at this performer are dissonant to cause musical tension. Finally, the last performer leaves the stage to resolve the tension, and the piece ends with three performers back in congruity.

Composer(s) Credits:

Bongjun Kim, Woon Seung Yeo

Instrumentalist(s) Credits:

Bongjun Kim (operator), Woon Seung Yeo, Jeong-seob Lee, Seunghun Kim, Xuelian Yu (iPhones)

Artist(s) Biography:

Bongjun Kim (b. 1981, Seoul, Korea) is a Masters student at Korea Advanced Institute of Science and Technology (KAIST) and a member of the Audio and Interactive Media (AIM) Lab at the Graduate School of Culture Technology (GSCT), KAIST. Kim has received his B.S. and M.S. degrees in Industrial and Information Systems Engineering from Ajou University, and he has also worked at Doosan Infracore as an R\&D researcher. He is also a composer, performer, and system developer of the KAIST Mobile Phone Orchestra (KAMPO), where he has designed interactive mobile music performance system and composed the piece ``Where Are You Standing?'' which features digital compass-based interaction. Currently his research interests are algorithmic composition, music informatics, machine improvisation, and mobile media as a new musical interface.

Woon Seung Yeo is a bassist, media artist, and computer music researcher/educator. He is Assistant Professor at Korea Advanced Institute of Science and Technology (KAIST) and leads the Audio and Interactive Media (AIM) Lab and the KAIST Mobile Phone Orchestra (KAMPO). Yeo has received degrees from Seoul National University (B.S. and M.S. in Electrical Engineering), University of California at Santa Barbara (M.S. in Media Arts and Technology), and Stanford University (M.A. and Ph.D. in Music). His research interests include digital audio signal processing, musical acoustics, audiovisual art, cross-modal display, physical interaction for music, musical interfaces, mobile media for music, and innovative performance paradigm as well. Yeo has also curated/produced mobile music concerts, telematics music concerts, and multimedia installations and exhibitions.

Jeong-seob Lee is a Ph.D. student at the Graduate School of Culture Technology (GSCT), KAIST, Korea, and a research member of Audio \& Interactive Media Lab. He received his M.S. degree from the same institute, and his undergraduate degree in mechanical engineering from Seoul National University. As an amateur dancer and choreographer, he is interested in various performances involving dance. His experiences on stage and in engineering lead him to conduct research in interactive performance paradigm and multimedia interface technology. He has produced a number of new media performances through collaborations with dancers and musicians, and worked as an audiovisual interaction designer. He is also interested in acoustic motion detection with off-the-shelf audio devices.

Seunghun Kim is a Ph.D. candidate at KAIST and is a member of Audio and Interactive Media (AIM) Lab in the Graduate School of Culture Technology (GSCT). He has received the B.S degree in electrical and communications engineering from Information and Communications University (ICU). He wrote his Master thesis on sound synthesis of the geomungo (a traditional Korean stringed instrument) at KAIST. He has presented several papers on musical interfaces at domestic/international conferences including the international conference on new interfaces for musical expression (NIME) and the international computer music conference (ICMC). In addition, he has participated in the development of interactive installations, which were exhibited at Incheon International Digital Art Festival (INDAF), KT\&G SangSang Madang, Gwangju Design Biennale, and Seoul Digital Media Content International Festival. He is also a member of the KAIST Mobile Phone Orchestra (KAMPO).

Xuelian Yu was born and raised in China and earned her B.S. in engineering at Jiangnan University's Digital Media Technology program. She joined the Audio and Interactive Media (AIM) Lab at the Graduate School of Culture Technology (GSCT), KAIST in the Fall of 2010 to combine her problem-solving skills and creative abilities to set up worlds that people become characters in the environments and interact with their surroundings. Xuelian is currently in Pittsburgh to discover more experience in projects that produce artifacts that are intended to entertain, inspire or affect the participants, at Entertainment Technology Center of Carnegie Mellon University and she focuses on the research on the comparison of description on surround sound at the same time.  The passion for learning and expanding her experiences has strengthened her goal to work in interactive design.

Concert Venue and Time: Lydia Mendelssohn Theatre, Tuesday May 22, 7:00pm
},
}

@InCollection{nime2012-music-Dahlstedt2012,
  author    = {Palle Dahlstedt},
  booktitle = {NIME'12 Program},
  title     = {Pencil Fields},
  year      = {2012},
  address   = {Ann Arbor, Michigan, U.S.A.},
  editor    = {Georg Essl and Brent Gillespie and Michael Gurevich and Sile O'Modhrain},
  month     = {May},
  day       = {21-23},
  publisher = {Electrical Engineering \& Computer Science and Performing Arts Technology, University of Michigan},
  note      = {Program notes:

An improvised performance on a custom built instrument, using a simple pencil drawing as a gestural interface for controlling complex analog synthesis. The interface works by using the resistive properties of carbon to create a voltage potential field in the graphite/pencil markings on the paper using custom movable electrodes, made from coins. Then, control voltages are extracted from other points on the paper, controlling various aspects of the synthesized sound. The design was inspired by my previous research in complex mappings for advanced digital instruments, and provides a similarly dynamic playing environment for analogue synthesis. The interface is very lo-tech, easy to build, and should be possible to use with any analogue modular synthesizer. Here, I use it with a Bugbrand modular, built by Tom Bugs in Bristol, UK. The interface is presented in more detail in a paper presentation at the NIME conference.

Composer(s) Credits:

Instrumentalist(s) Credits:

Palle Dahlstedt (pencil fields interface \& modular synthesizer)

Artist(s) Biography:

Palle Dahlstedt (b.1971), composer, improviser, pianist and researcher from Stockholm, since 1994 living in G\"{o}teborg, Sweden. With composition degrees from the Academies of Malm\"{o} and G\"{o}teborg and a PhD from Chalmers University of Technology in evolutionary algorithms for composition, he is currently the main lecturer in electronic music composition at the Academy of Music and Drama, University of Gothenburg, and artistic director the Lindblad Studios. Also, he is associate professor in computer-aided creativity at the Department of Applied IT, performing extensive research in novel technology-based performance and improvisation techniques for electronic and acoustic musicians, and in computer models of artistic creative processes. His music has been performed on six continents and received several awards, e.g., in 2001 he was awarded the prestigeous Gaudeamus Prize, as the first ever for an electronic work. He is also performing on piano with and without electronics, and in the electronic free impro duo pantoMorf.

Concert Venue and Time: Necto, Tuesday May 22, 9:00pm
},
}

@InCollection{nime2012-music-BrophyLabadie2012,
  author    = {Daniel Brophy and Colin Labadie},
  booktitle = {NIME'12 Program},
  title     = {Munich Eunuch},
  year      = {2012},
  address   = {Ann Arbor, Michigan, U.S.A.},
  editor    = {Georg Essl and Brent Gillespie and Michael Gurevich and Sile O'Modhrain},
  month     = {May},
  day       = {21-23},
  publisher = {Electrical Engineering \& Computer Science and Performing Arts Technology, University of Michigan},
  note      = {Program notes:

Many of the discourses around technological development in music are deeply concerned with aspects of control; i.e. how does one exert their control, or ``mastery'' over the technology they use. However, we propose that technological systems with a certain amount of unpredictability and randomness may also be useful, especially for improvisation. As an improvisation duo, our method often involves designing electronic instruments whose behaviors are somewhat unpredictable. As a result, our entire aesthetic is largely based on ``riding'' the boundary of control. Working in this way creates a situation where we are often forced to react to, and work with, the unexpected.

Our improvisation features a number of handmade and hacked electronic instruments, all of which have been designed to behave somewhat unpredictably.

Composer(s) Credits:

Instrumentalist(s) Credits:

Daniel Brophy (electronics), Colin Labadie (electronics)

Artist(s) Biography:

Daniel Brophy is a composer, performer and improviser of various musical styles and instrumentations ranging from orchestral and chamber music to extreme metal, sound installations, experimental improvisation and noise. He is a recipient of a SSHRC research grant, the 2012 KW Chamber Orchestra composition prize, the University of Alberta's President's Award of Distinction, and a Queen Elizabeth II Graduate Scholarship. Daniel currently resides in Edmonton, Alberta where he is pursuing a Doctor of Music degree in composition under the supervision of Dr. Scott Smallwood. He is member of the noise duo MUGBAIT and is proud to have worked with a number of other wonderful musicians, dancers and visual artists such as The Enterprise Quartet, junctQin, Digital Prowess, TorQ, Gerry Morita, Werner Friesen and many others. Daniel is currently developing interactive clothing for dancers, utilizing a combination of high and low technology.

Colin Labadie is a composer and performer currently based in Edmonton, Alberta. His musical output ranges from solo, chamber, choral, orchestral, and electroacoustic compositions, to sound installations, multimedia collaboration, experimental improvisation, and noise music. His work is shaped by a broad range of musical influences, at times dealing exclusively with repetition, patterns, and subtle variation, while at others exploring chaos and unpredictability.
Colin holds a BMus from Wilfrid Laurier University, where he studied with Linda Catlin Smith and Peter Hatch, and an MMus from the University of Alberta where he studied with Howard Bashaw, Mark Hannesson, Scott Smallwood, and Andriy Talpash. Currently, he is pursuing a Doctoral degree in Composition from the University of Alberta under the supervision of Scott Smallwood. He is the recipient of SSHRC's Joseph-Armand Bombardier Master's and Doctoral Scholarships, the University of Alberta Master's and Doctoral Recruitment Scholarships, and the President's Doctoral Prize of Distinction.

Concert Venue and Time: Necto, Tuesday May 22, 9:00pm
},
}

@InCollection{nime2012-music-FiggMcCormackCox2012,
  author    = {Jenn Figg and Matthew McCormack and Paul Cox},
  booktitle = {NIME'12 Program},
  title     = {Thunderclap For Six Kinetic Light Drums},
  year      = {2012},
  address   = {Ann Arbor, Michigan, U.S.A.},
  editor    = {Georg Essl and Brent Gillespie and Michael Gurevich and Sile O'Modhrain},
  month     = {May},
  day       = {21-23},
  publisher = {Electrical Engineering \& Computer Science and Performing Arts Technology, University of Michigan},
  note      = {Program notes:

This work merges sound and light to illuminate complex rhythmic motives, polyrhythms and metrical patterns in a visual display generated by three drummers playing six ``light'' drums. These new instruments bring to life the dreams of 20th century synesthetes, such as Wassily Kandinsky and Alexander Scriabin and others who sought to create an imagined ``visual music,'' an ideal synthesis of music and visual art.

Community Light Beacons are percussion instruments that leverage the potentials of music, analog technology, and human-generated power to visualize sound. These instruments add the dimension of light to the ancient tradition of drumming. The drums are user-powered, and when they are played---banged, hit and tapped---the vibrations from the drumhead are converted to electricity by the internal speaker transducer. The generated energy powers ultra bright LEDs, which light up with every hit and beam out from the Fresnel lens.

Composer(s) Credits:

Jenn Figg, Matthew McCormack, Paul Cox

Instrumentalist(s) Credits:

Ryan Hilty, Samuel Haese, Eric Young (Kinetic Light Drums)

Artist(s) Biography:

Jenn Figg is an artist investigating the connections between industry, science and art through the transformation of energy, performative objects and constructed ecosystems. She graduated with a BFA in Textiles from the Rhode Island School of Design and an MFA from the University of California at Santa Barbara. She is pursuing her Ph.D. in Media, Art, and Text at Virginia Commonwealth University. She lives in Baltimore and is an Assistant Professor of Art at Towson University in Maryland. Exhibitions include The Print Center in Philadelphia, Pennsylvania, The Art House at the Jones Center in Austin, Texas, Virginia MOCA in Virginia Beach, Virginia, the Columbus Center of Science and Industry in Columbus, Ohio, the Ingenuity Festival in Cleveland, Ohio. Other awards and residencies include the MacDowell Colony, the Lower Manhattan Cultural Council Residency, the Great Lakes College Association New Directions Initiative, and the University of California Interdisciplinary Humanities Center, Visual, Performing \& Media Arts Award.

Matthew McCormack explores energy transformation and expression through technology, kinetic sculpture and blown glass. He graduated with a BFA in Glass from The Ohio State University and is now living in Baltimore, Maryland. He is pursuing an Interdisciplinary MFA at Towson University. His research interests include modifying a speaker transducer for optimum energy generation and developing a series of rapid prototyped Fresnel lens stamps for quartz crystal light instruments. His work has been featured at the Virginia Museum of Contemporary Art in Virginia Beach, Virginia, the Columbus Center of Science and Industry in Columbus, Ohio, the Toledo Museum of Art in Toledo, Ohio, the Rankin Art Gallery at Ferris State University in Big Rapids, Michigan, the National Museum of Glass in Eskisehir, Turkey, the Franklin Park Conservatory in Columbus, Ohio, the Ingenuity Festival in Cleveland, Ohio, and as part of the Lower Manhattan Cultural Council's Governors Island Residency in New York City.

Paul Cox is a scholar, composer and percussionist in Cleveland, Ohio. He currently teaches music history and percussion at Case Western Reserve University (CWRU) and the Oberlin Conservatory of Music, where he is a Visiting Assistant Professor. He earned a PhD in musicology from CWRU in 2011 after the completion of his dissertation, \emph{Collaged Codes: John Cage's Credo in Us, a study of Cage and Merce Cunningham's first dance collaboration in 1942}. Current projects include composing \emph{Just.Are.Same} for string quartet, oboe and tape, which weaves together an electronic soundscape of spoken words drawn from victims of genocide with acoustic and electronic sounds; composing an evening-length work for the ensemble NO EXIT, in collaboration with famed world percussionist Jamie Haddad and guitarist Bobby Ferrazza; curating a Cage ``Musicircus'' for the opening of the new Museum of Contemporary Art in Cleveland, and artistically advising the Sitka Fest in Alaska, a three-month-long festival of arts and culture.

Ryan Hilty is a percussionist earning a degree in Music Education from the Case Western Reserve University School of Music in Cleveland, Ohio. He is currently in his second undergraduate year, studying percussion with Matthew Larson. He has performed as a percussionist in numerous ensembles, including the Crestwood Wind Ensemble, Jazz Band, and the Cleveland Youth Wind Symphony. He is the recipient of the 2010 John Phillip Sousa Award. After earning his degree in music education, Ryan aspires to become a high school band director.

Samuel Haese is a student of music and physics at Case Western Reserve University (CWRU) in Cleveland, OH.  He has studied concert percussion with Matthew Bassett, Feza Zweifel, and Matthew Larson, and currently collaborates with Paul Cox in exploring and performing modern percussion music. In the meantime, Sam is receiving a BA in Music for studying piano with Gerardo Teissonniere through the Cleveland Institute of Music. Sam intends to also receive a degree in Engineering Physics from CWRU which he hopes will allow him to explore and understand music technologies.  Originally from Berkeley, California, his current plans include moving to a sunnier place than Cleveland after graduation within the next two years.

Eric Young is a student at Case Western Reserve University majoring in Computer Science and Audio Engineering. He grew up in Kansas City, Missouri. He plans on incorporating his interests into a career developing digital audio software. Eric has been studying general percussion performance since 2003 and specializes in jazz drums.

Concert Venue and Time: Necto, Tuesday May 22, 9:00pm
},
}

@InCollection{nime2012-music-Tahiroglu2012,
  author    = {Koray Tahiro\u{g}lu},
  booktitle = {NIME'12 Program},
  title     = {InHands: Improvisation for Mobile Phones},
  year      = {2012},
  address   = {Ann Arbor, Michigan, U.S.A.},
  editor    = {Georg Essl and Brent Gillespie and Michael Gurevich and Sile O'Modhrain},
  month     = {May},
  day       = {21-23},
  publisher = {Electrical Engineering \& Computer Science and Performing Arts Technology, University of Michigan},
  note      = {Program notes:

\emph{InHands}, an audiovisual real-time improvisation for mobile phones, explores alternative options for musical interactions with two mobile instruments in live performances. In this improvisation piece, sound output of each mobile phone instrument becomes a sound input for the other instrument; to be processed further with an act of responding immediately and spontaneously. Granular synthesis module captures audio in real-time and creates the grains based on the texture of the sounds. Magnitude, roll and pitch values of the acceleration are mapped to the control parameters.  In the control layer of Sub-synthesis module, the change in direction of a touch position is tracked on the mobile surface and the distance of the same touch position to 4 certain points on the touchscreen is used as a source for creating frequency values. This mapping model generates 4 control parameters throughout 2 dimensional input layers. Hannah Drayson created the abstract visual-layers of this piece.

Composer(s) Credits:

Instrumentalist(s) Credits:

Koray Tahiro\u{g}lu (mobile phones)

Artist(s) Biography:

Koray Tahiro\u{g}lu is a musician, postdoctoral researcher and lecturer in the Department of Media, Aalto University. He practices art as a researcher focusing on embodied approaches to sonic interaction in participative music experience, as well as a performer of live electronic music. He conducted an artistic research with a focus on studying and practicing human musical interaction. Tahiro\u{g}lu has completed the degree of Doctor of Arts with the dissertation entitled "Interactive Performance Systems: Experimenting with Human Musical Interaction" after its public examination in 2008. He developed interactive performance systems and experimental musical instruments, which were used in his live performances. Since 2004, he has been also teaching workshops and courses introducing artistic strategies and methodologies for creating computational art works. Tahiro\u{g}lu has performed experimental music in collaboration as well as in solo performances in Europe and North America.

Concert Venue and Time: Necto, Tuesday May 22, 9:00pm
},
}

@InCollection{nime2012-music-Lorenzo2012,
  author    = {Levy Lorenzo},
  booktitle = {NIME'12 Program},
  title     = {Modified Attack},
  year      = {2012},
  address   = {Ann Arbor, Michigan, U.S.A.},
  editor    = {Georg Essl and Brent Gillespie and Michael Gurevich and Sile O'Modhrain},
  month     = {May},
  day       = {21-23},
  publisher = {Electrical Engineering \& Computer Science and Performing Arts Technology, University of Michigan},
  note      = {Program notes:

When designing my new electronic instruments, I always keep in mind the relationship between the instrument and performer as a tool and its master. The instrument should be a channel by which the performer can access the dimensions of sound in order to attempt to make music. The music should then originate from the musicians intention and not the instrument itself. Thus, I design my instruments as intuitive, transparent, and non-idiosyncratic mappings between physical gesture and sound.

This new electronic instrument remaps a Logitech Attack 3 Joystick to be able to control sound. Through the joystick, the performer can control volume, rhythm, repetition, and pitch of custom, preprogrammed sounds. Additionally, the joystick can be used to record and playback short audio loops. The product of this design allows for agile and intentional electronic musical gestures where rhythm, volume, and pitch are clear and deliberate. I have been able to reach a wide range of musical expressions and I am learning and discovering more as I practice MODIFIED ATTACK.

Composer(s) Credits:

Levy Lorenzo

Instrumentalist(s) Credits:

Levy Lorenzo

Artist(s) Biography:

Levy Lorenzo is an electronics engineer and percussionist living in New York. Specializing in microcontroller-based, he performs experimental, live-electronic \& acoustic music using new, custom electronic musical instruments and percussion. His work has been featured at STEIM in Amsterdam (NL), the Darmstadt School for New Music (DE) and the International Ensemble Moderne Academy (AU). Currently, Levy is a Live Sound Engineer for the International Contemporary Ensemble and Issue Project Room (Brooklyn, NY). Levy holds B.S. and M.Eng. degrees in Electrical \& Computer Engineering from Cornell University as well as an M.M. degree in Percussion Performance from Stony Brook University, where he is currently a D.M.A. candidate. [www.levylorenzo.com]

Concert Venue and Time: Necto, Tuesday May 22, 9:00pm
},
}

@InCollection{nime2012-music-Donnarumma2012,
  author    = {Marco Donnarumma},
  booktitle = {NIME'12 Program},
  title     = {Music for Flesh II, interactive music for enhanced body},
  year      = {2012},
  address   = {Ann Arbor, Michigan, U.S.A.},
  editor    = {Georg Essl and Brent Gillespie and Michael Gurevich and Sile O'Modhrain},
  month     = {May},
  day       = {21-23},
  publisher = {Electrical Engineering \& Computer Science and Performing Arts Technology, University of Michigan},
  note      = {Program notes:

Composer(s) Credits:

Marco Donnarumma

Instrumentalist(s) Credits:

Marco Donnarumma (Xth Sense)

Artist(s) Biography:

Marco Donnarumma: New media and sonic artist, performer and teacher, \textbf{Marco Donnarumma} was born in Italy and is based in Edinburgh, UK. Weaving a thread around biomedia research, musical and theatrical performance, participatory practices and subversive coding, Marco looks at the collision of critical creativity with humanized technologies. He has performed and spoken in 28 countries worldwide at leading art events, specialized festivals and academic conferences. Has been artist in residence at Inspace (UK) and the National School of Theatre and Contemporary Dance (DK). His work has been funded by the European Commission, Creative Scotland and the Danish Arts Council.  In February 2012 Marco was awarded the first prize in the Margaret Guthman Musical Instrument Competition (Georgia Tech Center for Music Technology, US) for the Xth Sense, a novel, biophysical interactive system named the ``world's most innovative new musical instrument''.

Concert Venue and Time: Necto, Tuesday May 22, 9:00pm
},
}

@InCollection{nime2012-music-Stine2012,
  author    = {Eli Stine},
  booktitle = {NIME'12 Program},
  title     = {Motion-Influenced Composition},
  year      = {2012},
  address   = {Ann Arbor, Michigan, U.S.A.},
  editor    = {Georg Essl and Brent Gillespie and Michael Gurevich and Sile O'Modhrain},
  month     = {May},
  day       = {21-23},
  publisher = {Electrical Engineering \& Computer Science and Performing Arts Technology, University of Michigan},
  note      = {Program notes:

This piece consists of a partially pre-composed acousmatic composition actualized in real time by hand motion. The audio generated by the hand motions is analyzed, colorized and projected beside the performer during the performance. The motions and content of this piece are inspired by the late Merce Cunningham and this performance is dedicated to him.

Composer(s) Credits:

Eli Stine

Instrumentalist(s) Credits:

Eli Stine

Artist(s) Biography:

Eli Stine (born 1991 in Greenville, NC) is a composer, programmer, and sound designer currently pursuing a Double Degree at Oberlin College, studying Technology In Music And Related Arts and composition in the conservatory and Computer Science in the college. Winner of the undergraduate award from the Society for Electro-Acoustic Music in the United States (SEAMUS) in 2011, Eli has studied with Tom Lopez, Lewis Nielson, and Per Bloland at Oberlin, focusing on electroacoustic and acoustic music, as well as live performance with electronics. While at Oberlin Eli has performed with Oberlin's Contemporary Music Ensemble, had works played in concert by Oberlin's Society of Composers, inc. ensemble and student ensemble ACADEMY, and collaborated with students and faculty across disciplines on collaborative multimedia projects. More information about Eli's work can be found at www.oberlin.edu/student/estine/.

Concert Venue and Time: Lydia Mendelssohn Theatre, Wednesday May 23, 7:00pm
},
}

@InCollection{nime2012-music-Ciufo2012,
  author    = {Thomas Ciufo},
  booktitle = {NIME'12 Program},
  title     = {Fragments},
  year      = {2012},
  address   = {Ann Arbor, Michigan, U.S.A.},
  editor    = {Georg Essl and Brent Gillespie and Michael Gurevich and Sile O'Modhrain},
  month     = {May},
  day       = {21-23},
  publisher = {Electrical Engineering \& Computer Science and Performing Arts Technology, University of Michigan},
  note      = {Program notes:

\emph{Fragments} is an improvisational performance piece that utilizes physical treatments inside an acoustic piano, as well as digital treatments provided by computer-based digital signal processing. In addition to using a few simple physical controls (foot pedals and custom iPad interface) this piece also uses the performed audio stream as a gestural control source. The preformed audio stream is analyzed and important features are extracted. The current state and trajectory of these audio features are used to influence the behavior of the real-time signal processing environment. This creates a computer-mediated performance system that combines the capabilities of computation and sound processing with the tactile and expressive intimacy of the prepared acoustic piano. \emph{Fragments} invites the listener into a unique and complex sonic environment where expectation, repetition, spontaneity, and discovery are intertwined.

Composer(s) Credits:

Thomas Ciufo

Instrumentalist(s) Credits:

Thomas Ciufo

Artist(s) Biography:

Thomas Ciufo is a composer, improviser, sound artist, and researcher working primarily in the areas of electroacoustic improvisational performance and hybrid instrument / interactive systems design. He currently serves as Assistant Professor of Recording Arts and Music Technology in the Department of Music at Towson University. He has been active for many years in the areas of composition, performance, interactive installation, video work, as well as music technology education. Festival performances include the SPARK festival in Minneapolis, the Enaction in Arts conference in Grenoble, the International Society for Improvised Music conference, the NWEAMO festival, the Extensible Electric Guitar Festival, various NIME conferences, and the ICMC / Ear to the Earth conference.

Concert Venue and Time: Lydia Mendelssohn Theatre, Wednesday May 23, 7:00pm
},
}

@InCollection{nime2012-music-Novello2012,
  author    = {Alberto Novello},
  booktitle = {NIME'12 Program},
  title     = {Fragmentation},
  year      = {2012},
  address   = {Ann Arbor, Michigan, U.S.A.},
  editor    = {Georg Essl and Brent Gillespie and Michael Gurevich and Sile O'Modhrain},
  month     = {May},
  day       = {21-23},
  publisher = {Electrical Engineering \& Computer Science and Performing Arts Technology, University of Michigan},
  note      = {Program notes:

In this piece we explore the personality of the ``post-modern man''. Exposed to aggressive stimulation and overwhelming data streams, he must make important choices to follow a rational ``mind path'' while his time quickly runs out. The performer, impersonating the post-modern man, wears an electro-encephalographic headset that detects his mind activity. The analysis of its output reveals the power of the performer's three thoughts which are connected to forward movement, turn left, and turn right in the virtual maze projected on a screen.

Despite the distracting external forces, embodied by the sound and flickering visuals, the performer must remain paradoxically calm to generate the correct states of mind that let him navigate his way out of the maze. Every time the performer crosses a red boundary in the maze, he gets closer to the exit, and a new stochastic musical scene is triggered. The time and structure of the composition is thus entirely determined by the choices and concentration of the performer.

Composer(s) Credits:

Alberto Novello

Instrumentalist(s) Credits:

Alberto Novello (music, EEG analysis, top visuals), Emmanuel Elias Flores (frontal visuals), Honza Svasek (Butoh, EEG control), E. McKinney (photography)

Artist(s) Biography:

Alberto Novello a.k.a. JesterN studied piano and double bass at the Conservatory of Udine, graduated in Physics at the University of Trieste, he completed in 2004 the master ``Art, Science and Technologies'' at the Institut National Polytechnique of Grenoble, France, under the guidance of J.C. Risset, and C. Cadoz. He was teacher of electronic music composition at the Conservatory of Cuneo, Italy. From 2004 to 2009 he worked at the Philips Research, Eindhoven, Netherlands, in the field of Music Perception and Music Information Retrieval with several publications in international conferences and journals. In 2009 he received a PhD degree at the Technische Universiteit Eindhoven. He attended the Mater of Sonology under the guidance of Paul Berg, Joel Ryan, and Richard Barret. Since 2004 he produced several electronic audio visual pieces assisting among others Alvin Lucier, Trevor Wishart, and Butch Morris. His pieces can be found on his website: http://dindisalvadi.free.fr/.

Honza Svasek was born in 1954 in the Netherlands. After his studies he
moved to Copenhagen were he became a graphic designer. Then he worked as computer professional and became a UNIX/Linux expert. In present he is a visual artist and performer. Honza started his research of Butoh 5 years ago. He studied with Butoh performers such as Itto Morita, Atsushi Takenouchi, Ken May, Yumiko Yoshioka,Yuko Ota, Imre Thormann. Currently he is studying with Rhizome Lee at the Himalaya Subbody Butoh School. http://Honz.nl

Emmanuel Elias Flores is a media designer and software artist based in the Netherlands. He studied music and cinema in Mexico and Sonology at the Royal Conservatory in The Hague (NL). His work is centered around the idea of exploring different types of cinematic experiences and the enhancement of new narrative forms which bridge technology, art and perception. His work has been presented on a wide range of formats: from audiovisual pieces for electronic music, opera, dance and live cinema sets, to the design of public installations and interactive applications for mobile devices. In parallel to his creative activities he has worked as a developer and IT/video consultant for different commercial and art enterprises and as a programmer for portable devices. www.emmanuelflores.net

Concert Venue and Time: Lydia Mendelssohn Theatre, Wednesday May 23, 7:00pm
},
}

@InCollection{nime2012-music-TrailKellOdowichuk2012,
  author    = {Shawn Trail and Thor Kell and Gabrielle Odowichuk},
  booktitle = {NIME'12 Program},
  title     = {M\aa ne Havn (mounhoun): An Exploration of Gestural Language for Pitched Percussion},
  year      = {2012},
  address   = {Ann Arbor, Michigan, U.S.A.},
  editor    = {Georg Essl and Brent Gillespie and Michael Gurevich and Sile O'Modhrain},
  month     = {May},
  day       = {21-23},
  publisher = {Electrical Engineering \& Computer Science and Performing Arts Technology, University of Michigan},
  note      = {Program notes:

\emph{M\aa ne Havn (mounhoun)} is an improvisational multi-media performance system for extended vibraphone with accompanying custom LED sculptures and projected visuals. The music draws specifically from NYC free jazz, the funeral music of the Lobi people of northern Ghana, Dub, psych rock and minimalism. Abstract interactive light sculptures actuated from the instrument's audio and controller data will accompany the performance, creating a visually shifting immersive space. The sculptures, named `Takete' and `Maluma', reference Gestalt psychology and the known correlation between our perceptions of sound and light. Mappings will reflect this phenomenon. The piece uses a pitched percussion tool suite developed by the Music Intelligence \& Sound Technology Collective at the University of Victoria, including: Magic Eyes (3D gesture controller), Ghost Hands (control data looper), MSTR DRMMR++ (rhythm template as control switches), Fantom Faders (vibraphone bars as control faders) and Gyil Gourd (physical modeling of the Lobi xylophone's gourd resonator).

Composer(s) Credits:

Shawn Trail, Thor Kell, Gabrielle Odowichuk (Artistic Director)

Instrumentalist(s) Credits:

Shawn Trail (xtended Vibraphone, Notomoton- robotic drum, suspended cymbal)

Artist(s) Biography:

Shawn Trail: Electro-acoustic percussionist, \textbf{Shawn Trail}, designs and builds new performance technologies for acoustic pitched percussion instruments integrating musical robotics, physical modeling synthesis, and HCI. He was Control Interface and Robotics Technician for Pat Metheny's Orchestrion World Tour (2010), Fulbright Scholar at Medialogy- Aalborg University, Copenhagen researching DSP, synthesis, and HCI (2009), and composer-in-residence with League of Electronic Musical Urban Robots (2008). In 2002 he conducted field research in Ghana on the Gyil (traditional xylophone). He has a Master of Music in Studio Composition from Purchase Conservatory of Music and a BA in percussion performance and music technology. He is an Interdisciplinary PhD candidate in Computer Science, Electrical Engineering, and Music with MISTIC at the University of Victoria. Performing solo under the moniker TXTED, his multi- media performance works singularly revolve around minimal, textural evolving polyrhythmic, melodic ostinati propelled by a sense of urgency intrinsic to cultural music rituals informed by specific traditions.

Thor Kell: As a composer, programmer, and DJ, \textbf{Thor Kell} likes combining interesting things in unique ways. A recent graduate of the University of Victoria's Music / Computer Science program, he will begin his MA at McGill University in the fall, focusing on interactions between performer, interface, and software. While at UVic, he received a Jamie Cassels Undergraduate Research Award: his research involved prototyping and composing for a gestural control mapping system for extending the marimba. His traditional compositions are all clockwork riffs and hidden structures, based on mathematical constants or time- stretched quotes from the English folk music canon: he has written for everything from full orchestra to solo piano. He has programmed for The Echo Nest and SoundCloud. In his secret life as a DJ and techno maven, he has released chart-toppers on Kompakt, impossibly deep jams on Fade, and hour-long remix / video symphonies on his own label, Tide Pool.

Gabrielle Odowichuk is a graduate student in Electrical Engineering at the University of Victoria, working in the MISTIC research lab. A specialist in DSP and MIR, her research has focused on sound spatialization and gesture-based control of sound and music, developing a variety of prototypes, including Fantom Faders and Magic Eyes, the mallet tracking and gesture control applications used in this performance. For M\o{a}ne Havn (mounhoun), she draws on previous experience in art direction and stage design to produce unique real-time gesture-controlled visualizations. She designed, built, and developed the interactive LED sculptures, Takete and Maluma, used in this piece, as well as the projections. Her work has been published by ICMC, IEEE, and NIME.

Concert Venue and Time: Lydia Mendelssohn Theatre, Wednesday May 23, 7:00pm
},
}

@InCollection{nime2012-music-Caldwell2012,
  author    = {James Caldwell},
  booktitle = {NIME'12 Program},
  title     = {Texturologie 12: Gesture Studies},
  year      = {2012},
  address   = {Ann Arbor, Michigan, U.S.A.},
  editor    = {Georg Essl and Brent Gillespie and Michael Gurevich and Sile O'Modhrain},
  month     = {May},
  day       = {21-23},
  publisher = {Electrical Engineering \& Computer Science and Performing Arts Technology, University of Michigan},
  note      = {Program notes:

\emph{Texturologie 12: Gesture Studies} (2011) is the most recent of my series of pieces that explore the creation of intricate continuous-field textures (and borrow the name of a series of paintings by Dubuffet). In this piece, I return to my explorations of the potential of the Wii\texttrademark remote to control computer music in performance. This time, I tried to treat the physical gesture as the germ or motive for the music. Some of the gestures are abstract, but some are suggestive of familiar activities like petting a cat, ringing a bell, smoothing wallpaper , playing a guiro, scooping, tapping, or vigorous stirring. (Check out the videos of my other Wiii\texttrademark pieces on YouTube. Search ``Caldwell wii.'')

Composer(s) Credits:

James Caldwell

Instrumentalist(s) Credits:

James Caldwell (Wii remotes)

Artist(s) Biography:

James Caldwell (b. 1957) is Professor of Music at Western Illinois University and co-director of the New Music Festival. He was named Outstanding Teacher in the College of Fine Arts and Communication (2005) and received the inaugural Provost's Award for Excellence in Teaching. He was named the 2009 Distinguished Faculty Lecturer. He holds degrees from Michigan State University and Northwestern University, where he studied composition, theory, and electronic and computer music. Since 2004 he has studied studio art---drawing, lithography, painting, and sculpture---at WIU as a way to stretch creatively and again experience being a student.

Concert Venue and Time: Lydia Mendelssohn Theatre, Wednesday May 23, 7:00pm
},
}

@InCollection{nime2012-music-SchanklerFrancoisChew2012,
  author    = {Isaac Schankler and Alexandre Fran\c{c}ois and Elaine Chew
},
  booktitle = {NIME'12 Program},
  title     = {Mimi: Multi-modal Interaction for Musical Improvisation},
  year      = {2012},
  address   = {Ann Arbor, Michigan, U.S.A.},
  editor    = {Georg Essl and Brent Gillespie and Michael Gurevich and Sile O'Modhrain},
  month     = {May},
  day       = {21-23},
  publisher = {Electrical Engineering \& Computer Science and Performing Arts Technology, University of Michigan},
  note      = {Program notes:

Mimi, designed by Alexandre Fran\c{c}ois with input from Elaine Chew and Isaac Schankler, is a multi-modal interactive musical improvisation system that explores the impact of visual feedback in performer-machine interaction. The Mimi system enables the performer to experiment with a unique blend of improvisation-like on-the-fly invention, composition-like planning and choreography, and expressive performance. Mimi's improvisations are created through a factor oracle. The visual interface gives the performer and the audience instantaneous and continuous information on the state of the oracle, its recombination strategy, the music to come, and that recently played. The performer controls when the system starts, stops, and learns, the playback volume, and the recombination rate. Mimi is not only an effective improvisation partner, it also provides a platform through which to interrogate the mental models necessary for successful improvisation. This performance also features custom synths and mechanisms for inter-oracle interaction created for Mimi by Isaac Schankler.

Composer(s) Credits:

Isaac Schankler, Alexandre Fran\c{c}ois, Elaine Chew

Instrumentalist(s) Credits:

Isaac Schankler (keyboard \& electronics), Mimi (keyboard \& electronics)

Artist(s) Biography:

Isaac Schankler is a Los Angeles-based composer-improviser. His recent honors include a grant from Meet the Composer for his opera Light and Power, selection as finalist in the ASCAP/SEAMUS Composition Competition, and the Damien Top Prize in the ASCAP/Lotte Lehmann Foundation Art Song Competition. He is the Artist in Residence of the Music Computation and Cognition Laboratory (MuCoaCo) at the USC Viterbi School of Engineering, and an Artistic Director of the concert series People Inside Electronics. Isaac holds degrees in composition from the USC Thornton School of Music (DMA) and the University of Michigan (MM, BM).

Elaine Chew is Professor of Digital Media at Queen Mary, University of London, and Director of Music Initiatives at the Centre for Digital Music. An operations researcher and pianist by training, her research goal is to de-mystify music and its performance through the use of formal scientific methods; as a performer, she collaborates with composers to present eclectic post-tonal music. She received PhD and SM degrees in Operations Research from MIT and a BAS in Music and Mathematical \& Computational Sciences from Stanford. She is the recipient of NSF Career and PECASE awards, and a Radcliffe Institute for Advanced Studies fellowship.

Alexandre R.J. Fran\c{c}ois's research focuses on the modeling and design of interactive (software) systems, as an enabling step towards the understanding of perception and cognition. He was a 2007-2008 Fellow of the Radcliffe Institute for Advanced Study at Harvard University, where he co-led a music research cluster on Analytical Listening Through Interactive Visualization. Fran\c{c}ois received the Dipl\^{o}me d'Ing\'{e}nieur from the Institut National Agronomique Paris-Grignon in 1993, the Dipl\^{o}me d'Etudes Approfondies (M.S.) from the University Paris IX - Dauphine in 1994, and the M.S. and Ph.D. degrees in Computer Science from the University of Southern California in 1997 and 2000 respectively.

Concert Venue and Time: Lydia Mendelssohn Theatre, Wednesday May 23, 7:00pm
},
}

@InCollection{nime2012-music-StapletonDavis2012,
  author    = {Paul Stapleton and Tom Davis},
  booktitle = {NIME'12 Program},
  title     = {Ambiguous Devices},
  year      = {2012},
  address   = {Ann Arbor, Michigan, U.S.A.},
  editor    = {Georg Essl and Brent Gillespie and Michael Gurevich and Sile O'Modhrain},
  month     = {May},
  day       = {21-23},
  publisher = {Electrical Engineering \& Computer Science and Performing Arts Technology, University of Michigan},
  note      = {Program notes:

This performance explores notions of presence and absence, technologically mediated communication and audience perception through the staging of intentionally ambiguous but repeatable sonic interactions taking place across two geographically separate locations.

Thanks to SARC, CCRMA \& Bournemouth University for support during the development of this project.

Composer(s) Credits:

Paul Stapleton and Tom Davis

Instrumentalist(s) Credits:

Paul Stapleton (Networked Instrument), Tom Davis (Networked Instrument)

Artist(s) Biography:

Paul Stapleton is a sound artist, improviser and writer originally from Southern California, currently based in Belfast, Northern Ireland. Paul designs and performs with a variety of modular metallic sound sculptures, custom made electronics, found objects and electric guitars in locations ranging from experimental music clubs in Berlin to remote beaches on Vancouver Island. He is currently involved in a diverse range of artistic collaborations including: performance duo ABODE with vocalist Caroline Pugh, interdisciplinary arts group theybreakinpieces, improvisation duo with saxophonist Simon Rose, Eric Lyon's Noise Quartet, and the DIY quartet E=MCHammer. Since 2007, Paul has been on the faculty at the Sonic Arts Research Centre where he teaches and supervises Master's and PhD research in performance technologies, interaction design and site-specific art.

Tom Davis  is a digital artist working mainly in the medium of sound installation. His practice and theory based output involves the creation of technology-led environments for interaction. He performs regularly as part of JDTJDJ with Jason Dixon and as part of the Jackson4s. He has performed and exhibited across Europe and in the US. Davis is currently a lecturer at the University of Bournemouth and holds a PhD from the Sonic Arts Research Centre.

Concert Venue and Time: Lydia Mendelssohn Theatre, Wednesday May 23, 7:00pm
},
}

@InCollection{nime2012-music-Blasco2012,
  author    = {Mercedes Blasco},
  booktitle = {NIME'12 Program},
  title     = {The Theremin Orchestra},
  year      = {2012},
  address   = {Ann Arbor, Michigan, U.S.A.},
  editor    = {Georg Essl and Brent Gillespie and Michael Gurevich and Sile O'Modhrain},
  month     = {May},
  day       = {21-23},
  publisher = {Electrical Engineering \& Computer Science and Performing Arts Technology, University of Michigan},
  note      = {Program notes:

\emph{The Theremin Orchestra} is a composition for three voices and a modular system of four spheres with built-in Theremin Sensors. Two of those spheres will control different effects on the voices and the rest will be played as Theremin instruments. The performance is presented as a sound event where initially the three voices appear raw and naked and as the composition unfolds the voices will be increasingly distorted through different effects applied with the Theremin controllers. In the climax of its progression the other two Theremin balls will become audible merging their sound with the mesh of vocal reshaped sources, not allowing to distinguish where the human ends and the machine starts.

Composer(s) Credits:

Mercedes Blasco

Instrumentalist(s) Credits:

Mercedes Blasco (voice, Theremin controllers, EMS synth), Thessia Machado and Sonia Meg\'{i}as (voice, Theremin instrument)

Artist(s) Biography:

Merche Blasco: Trained as a Telecommunications Engineer, \textbf{Merche Blasco} developed in parallel to her studies a more creative path related with music, video, installation and performance. She created her alter ego ``Burbuja'' as a vehicle for her own musical exploration and since its conception she has participated \& collaborated with various artists, establishing a strong relationship between different mediums of artistic expression  \& her own musical direction lsuch as Lucy Orta at the Venice biennale, Chicks on Speed and Cristian Vogel.
Her debut,``burbuja'' (station55 records) was presented in Sonar 2007 and has been touring in different cities in Europe, USA and Canada in the past years: Mapping Festival (Geneve), Sonic Art Circuits (Washington), Queens Museum of Art (New York). Thanks to a Fulbright Grant she is currently a MPS Candidate in the Interactive Telecommunications Program (NYU) where she is mainly researching about new tools for Electronic Music Performance.

Thessia Machado, Brazil/NY, investigates the physicality of sound and its effect on our perception of space. Many of her recent sculptures and installations function also as unorthodox instruments---pieces that have a real-time, live component. The expressive potential is active and changeable as the viewer interacts and performs with it. Thessia's installations and video pieces have been exhibited in New York, London, Philadelphia, Paris, Amsterdam, Dublin, Berlin and Athens.
She has been awarded residencies at the MacDowell Colony, Yaddo, the Atlantic Center for the Arts, the Irish Museum of Modern Art and the Vermont Studio Center and she is a recipient of fellowships from the New York Foundation for the Arts, The Experimental Television Center and The Bronx Museum. Performing as link, Thessia Machado, a self-avowed noisician, employs a changing line-up of handmade, found and modified instruments to build driving, meditative soundscapes.

Sonia Megias was born on June 20th 1982 in Almansa, a village at the southeast of Spain. Since she was a kid, she has been abducted by the arts, nature and spirituality. Even today, some years later, she tries to interweave these beautiful disciplines, with the goal of transmit to the world her perception of Beauty or True.
Thanks to the intensity of her musical production, she finds herself living in New York since 2010, on the Fulbright and a NYU Steinhardt grants. Here, she combines her studies at the New York University with the compositions of her last commissioned pieces.
Her music has been performed in different music halls and festivals, underlining the following: Auditorio 400 at the National Museum of Contemporary Art ``Queen Sophia'' (2012, 2008); Cervantes Institute of New York (2012, 2011); Houston University, at Opera Vista Festival (2011); Consulate of Argentina in New York, at a Tribute to Alfonsina Storni (2009); Embassy of France in Spain (2009); United Nations Headquarters (2008).

Concert Venue and Time: Necto, Wednesday May 23, 9:00pm
},
}

@InCollection{nime2012-music-Dupuis2012,
  author    = {Alexander Dupuis},
  booktitle = {NIME'12 Program},
  title     = {Stelaextraction},
  year      = {2012},
  address   = {Ann Arbor, Michigan, U.S.A.},
  editor    = {Georg Essl and Brent Gillespie and Michael Gurevich and Sile O'Modhrain},
  month     = {May},
  day       = {21-23},
  publisher = {Electrical Engineering \& Computer Science and Performing Arts Technology, University of Michigan},
  note      = {Program notes:

\emph{Stelaextraction} uses the electronic extension capabilities of the Yerbanaut to construct a musical composition through self-reference across different timescales. The Yerbanaut is a custom electro-acoustic kalimba built from a yerba mate gourd, with the tines placed in a circular pattern rather than the usual horizontal arrangement. Its sensors are intended to make use of this new arrangement, with force-sensitive buttons giving the otherwise inert left hand expressive capabilities, and a distance sensor allowing the right hand's motion to determine aspects of the processing. In Stelaextraction, all acoustic and processed sounds are recorded to a single buffer, the contents of which can be scrubbed through using the right hand's distance sensor. In this way, past musical gestures can be explored and then re-explored, with the recursive processing developing self-similar musical patterns over the course of the piece.

Composer(s) Credits:

Alexander Dupuis

Instrumentalist(s) Credits:

Alexander Dupuis (Yerbanaut)

Artist(s) Biography:

Alexander Dupuis develops real-time audiovisual feedback systems mediated by performers, sensors, musicians, matrices, bodies, scores, games, and environments. He also composes, arranges and performs sounds for guitars, liturgies, chamber groups, horse duos, microwave cookbooks, and celebrity voices. He graduated from Brown University's MEME program as an undergraduate in 2010, and is now in his second year of the Digital Musics masters program at Dartmouth College.

Concert Venue and Time: Necto, Wednesday May 23, 9:00pm
},
}

@InCollection{nime2012-music-Burns2012,
  author    = {Christopher Burns},
  booktitle = {NIME'12 Program},
  title     = {Fieldwork},
  year      = {2012},
  address   = {Ann Arbor, Michigan, U.S.A.},
  editor    = {Georg Essl and Brent Gillespie and Michael Gurevich and Sile O'Modhrain},
  month     = {May},
  day       = {21-23},
  publisher = {Electrical Engineering \& Computer Science and Performing Arts Technology, University of Michigan},
  note      = {Program notes:

\emph{Fieldwork} is a software environment for improvised performance with electronic sound and animation. Two musicians' sounding performances are fed into the system, and analyzed for pitch, rhythm, and timbral change. When the software recognizes a sharp contrast in one performer's textures or gestures, it reflects this change by transforming the sound of the other musician's performance. Not only are the musicians responding to one another as in conventional improvisation, but they are also able to directly modify their duo partner's sound through the software. Fieldwork emphasizes rapid, glitchy, and polyrhythmic distortions of the musician's performances, and establishes unpredictable feedback processes that encourage unexpected improvisational relationships between the performers and computer.

Composer(s) Credits:

Christopher Burns

Instrumentalist(s) Credits:

Christopher Burns,  Andrew Bishop

Artist(s) Biography:

Christopher Burns is a composer, improviser, and multimedia artist. His instrumental chamber works weave energetic gestures into densely layered surfaces. Polyphony and multiplicity also feature in his electroacoustic music, embodied in gritty, rough-hewn textures. As an improviser, Christopher combines an idiosyncratic approach to the electric guitar with a wide variety of custom software instruments. Recent projects emphasize multimedia and motion capture, integrating performance, sound, and animation into a unified experience. Across these disciplines, his work emphasizes trajectory and directionality, superimposing and intercutting a variety of evolving processes to create form.
Christopher is an avid archaeologist of electroacoustic music, creating and performing new digital realizations of classic music by composers including Cage, Ligeti, Lucier, Nancarrow, Nono, and Stockhausen. A committed educator, he teaches music composition and technology at the University of Wisconsin-Milwaukee. He has studied composition with Brian Ferneyhough, Jonathan Harvey, Jonathan Berger, Michael Tenzer, and Jan Radzynski.

Andrew Bishop is a versatile multi-instrumentalist, composer, improviser, educator and scholar comfortable in a wide variety of musical idioms.  He maintains a national and international career and serves as an Assistant Professor of Jazz and Contemporary Improvisation at the University of Michigan in Ann Arbor.  Bishop's two recordings as a leader have received widespread acclaim from \emph{The New York Times, Downbeat Magazine, Chicago Reader, All Music Guide, Cadence Magazine, All About Jazz-New York, All About Jazz-Los Angeles, and the Detroit Free Press}, among others.  As a composer and arranger he has received over 20 commissions, numerous residencies and awards and recognition from ASCAP, the Chicago Symphony Orchestra, the Andrew W. Melon Foundation, the National Endowment for the Arts, Chamber Music of America and a nomination from the American Academy of Arts and Letters.  He has performed with artist in virtually every musical genre.  He earned five degrees in music including a D.M.A. in music composition from the University of Michigan.

Concert Venue and Time: Necto, Wednesday May 23, 9:00pm
},
}

@InCollection{nime2012-music-Uozumi2012,
  author    = {Yuta Uozumi and Keisuke Oyama and Jun Tomioka and Hiromi Okamoto and Takayuki Kimura},
  booktitle = {NIME'12 Program},
  title     = {four fragments---A Performance for Swarming Robotics},
  year      = {2012},
  address   = {Ann Arbor, Michigan, U.S.A.},
  editor    = {Georg Essl and Brent Gillespie and Michael Gurevich and Sile O'Modhrain},
  month     = {May},
  day       = {21-23},
  publisher = {Electrical Engineering \& Computer Science and Performing Arts Technology, University of Michigan},
  note      = {Program notes:

This performance aims to approach the next style of ``mashup'' and/or ``Cut-up'' via fusion of paradigms of artificial-life and turntable. We developed a system named ``SoniCell'' to realize it. SoniCell employs four robots called ``cell''. Each cell behaves as a metaphor of life based on a simple interaction model with prey-predator relationship. Each cell is assigned a music-track in the manner of turntable. Therefore, the system reconstructs and mixes the music-tracks via cells' interactions and performers' interventions. In this framework, the aspects of the system and performers interactions and cells' internal-states create structures of sounds and music from different tracks.

Composer(s) Credits:

Yuta Uozumi, Keisuke Oyama, Jun Tomioka, Hiromi Okamoto, Takayuki Kimura

Instrumentalist(s) Credits:

Artist(s) Biography:

Yuta Uozumi is a sound artist and agent-base composer was born in the suburbs of Osaka, Japan. He started computer music at the age of fifteen. He received his Ph.D. from Keio University SFC Graduate School of Media and Governance. He is researching and teaching at Tokyo University of Technology. He is studying Multi-Agent based dynamic composition with computer or human ensembles. In 2002 His CD "meme?" was released from Cubicmusic Japan (under the name of SamuraiJazz). In 2003 agent-based musical interface "Chase" was accepted by NIME. It is a collaborative project by system-designer, DSP engineer and performer. In 2005 an application for agent-based composition ``Gismo'' and a piece created with the system ``Chain'' (early version) were accepted by ICMC(International Computer Music Conference).

Keisuke Oyama, was born in Kumamoto, Japan on September 19, 1986. He plays various instruments freely in childhood. When he was 18, moved to Tokyo to study jazz theory. After starting his career as a jazz musician, he participated various sessions as a guitarist. Furthermore, his interest covered electro acoustic in the career. He was enrolled at Keio University Shonan Fujisawa Campus (SFC) to learn method and technique of computer music and media art in 2009. He is exploring the new expression of music.

Concert Venue and Time: Necto, Wednesday May 23, 9:00pm
},
}

@InCollection{nime2012-music-Tremblay2012,
  author    = {Pierre~Alexandre Tremblay},
  booktitle = {NIME'12 Program},
  title     = {Sandbox\#3.6},
  year      = {2012},
  address   = {Ann Arbor, Michigan, U.S.A.},
  editor    = {Georg Essl and Brent Gillespie and Michael Gurevich and Sile O'Modhrain},
  month     = {May},
  day       = {21-23},
  publisher = {Electrical Engineering \& Computer Science and Performing Arts Technology, University of Michigan},
  note      = {Program notes:

A bass guitar and a laptop.

No sequence, no set list, no programme, no gizmo, no intention, no fireworks, no meaning, no feature, no beat, no argument, no nothing.

Just this very moment with my meta-instrument: a third sandbox in which I play in public for the sixth time, here, whatever happens.

Composer(s) Credits:

Instrumentalist(s) Credits:

Pierre Alexandre Tremblay

Artist(s) Biography:

Pierre Alexandre Tremblay (Montr\'{e}al, 1975) is a composer and a performer on bass guitar and sound processing devices, in solo and within the groups ars circa music\ae (Paris, France), de type inconnu (Montr\'{e}al, Qu\'{e}bec), and Splice (London, UK). His music is mainly released by Empreintes DIGITALes and Ora. He is Reader in Composition and Improvisation at the University of Huddersfield (UK) where he also is Director of the Electronic Music Studios. He previously worked in popular music as producer and bassist, and is interested in videomusic and coding. He likes oolong tea, reading, and walking. As a founding member of the no-tv collective, he does not own a working television set. www.pierrealexandretremblay.com

Concert Venue and Time: Necto, Wednesday May 23, 9:00pm
},
}

@InCollection{nime2012-music-dAlessandroSchwarz2012,
  author    = {Nicolas d'Alessandro and, Diemo Schwarz},
  booktitle = {NIME'12 Program},
  title     = {DaisyLab, a Phonetic Deconstruction of Humankind},
  year      = {2012},
  address   = {Ann Arbor, Michigan, U.S.A.},
  editor    = {Georg Essl and Brent Gillespie and Michael Gurevich and Sile O'Modhrain},
  month     = {May},
  day       = {21-23},
  publisher = {Electrical Engineering \& Computer Science and Performing Arts Technology, University of Michigan},
  note      = {Program notes:

\emph{DaisyLab} is a duet performance for two new interfaces for musical expression that have in common the ability to generate versatile vocal material. Diemo Schwarz's instrument uses a variety of sensors on the top of corpus-based concatenative synthesis, which has been fed with voice sounds for this performance. Nicolas d'Alessandro plays the HandSketch interface over the new MAGE speech synthesizer, bringing tangible inputs to an emerging speech synthesis technique. Both systems have been submitted as long papers for this 2012 edition of NIME. Together these two performers explore the boundaries between vocal and non-vocal sonic spaces, aiming at deconstructing the humankind's most ubiquitous communicative channel through a compositionally directed improvisation, a ``comprovisation.''

Composer(s) Credits:

Instrumentalist(s) Credits:

Nicolas d'Alessandro (HandSketch, iPad), Diemo Schwarz (CataRT, gestural controllers)

Artist(s) Biography:

Nicolas d'Alessandro obtained his PhD in Applied Sciences from the University of Mons in 2009. From a lifelong interest in musical instruments and his acquired taste in speech and singing processing, he will incrementally shape a research topic that aims at using gestural control of sound in order to gain insights in speech and singing production. He works with Prof. T. Dutoit for a PhD at the University of Mons between 2004 and 2009. Late 2009, he moves to Canada, to take a postdoc position with Prof. S. Fels at the MAGIC Lab, University of British Columbia, where he will work on the DiVA project. There he will also organize the first p3s workshop. Since December 2011, he is back in the University of Mons and leads the MAGE project. Nicolas is also an active electroacoustic performer in and around Belgium, playing guitar and invented instruments in various performances.

Concert Venue and Time: Necto, Wednesday May 23, 9:00pm
},
}
@inproceedings{nime19-music-Rust,
  author = {Anna R{\"u}st},
  title = {Bad Mother / Good Mother - an audiovisual performance},
  pages = {8--10},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Federico Visi},
  year = {2019},
  month = {June},
  publisher = {UFRGS},
  address = {Porto Alegre, Brazil},
  URL = {http://www.nime.org/proceedings/2019/nime2019_music001.pdf},
  abstract = {Bad Mother / Good Mother is an audiovisual performance involving a projection, a modified electronic breast pump as a sound generator, and a sound- reactive LED pumping costume. The project has four songs that critically explore technologies directed specifically at women like breast pumps and fertility extending treatments such as egg-freezing (social freezing). Depending on the song, the breast pump is either a solo instrument or part of an arrangement. The idea is to use workplace lactation as a departure point to uncover a web of societal politics and pre-conceived perceptions (pun intended) of ideal and non-ideal motherhood.}
}

@inproceedings{nime19-music-DAlessandro,
  author = {Christophe D'Alessandro and Xiao Xiao and Grégoire Locqueville and Boris Doval},
  title = {Borrowed Voices},
  pages = {11--14},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Federico Visi},
  year = {2019},
  month = {June},
  publisher = {UFRGS},
  address = {Porto Alegre, Brazil},
  URL = {http://www.nime.org/proceedings/2019/nime2019_music001.pdf},
  abstract = {Borrowed voices is a performance featuring performative voice synthesis, with two types of instruments: C-Voks and T-Voks. The voices are played a cappella in a double choir of natural and synthetic voices. Performative singing synthesis is a new paradigm in the already long history of artificial voices. The singing voice is played like an instrument, allowing singing with the borrowed voice of another. The relationship of embodiment between the singer's gestures and the vocal sound produced is broken. A voice is singing, with realism, expressivity and musicality, but it is not the musician's own voice, and a vocal apparatus does not control it. The project focuses on control gestures: the music explores vocal sounds produced by the vocal apparatus (the basic sound material), and “played” by the natural voice, by free-hand Theremin-controlled gestures, and by writing gestures on a graphic tablet. The same (types of) sounds but different gestures give different musical “instruments” and expressive possibilities. Another interesting aspect is the distance between synthetic voices and the player, the voice being at the same time embodied (by the player gestures playing the instrument with her/his body) and externalized (because the instrument is not her/his own voice): two different voices sung/played by the same person.}
}

@inproceedings{nime19-music-Dooley,
  author = {James Dooley},
  title = {colligation},
  pages = {15-16},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Federico Visi},
  year = {2019},
  month = {June},
  publisher = {UFRGS},
  address = {Porto Alegre, Brazil},
  URL = {http://www.nime.org/proceedings/2019/nime2019_music003.pdf},
  abstract = {colligation (to bring or tie together) is a physical performance work for one performer that explores the idea of sculpting sound through gesture. Treating sound as if it were a tangible object capable of being fashioned into new sonic forms, "pieces" of sound are captured, shaped and sculpted by the performer's hand and arm gestures, appearing pliable as they are thrown around and transformed into new sonic material. colligation uses two Thalmic Labs Myo armbands, one placed on the left arm and the other on the right arm. The Myo Mapper [1] software is used to transmit scaled data via OSC from the armbands to Pure Data. Positional (yaw, pitch and roll) and electromyographic data (EMG) from the devices are mapped to parameters controlling a hybrid synth created in Pure Data. The synth utilises a combination of Phase Aligned Formant synthesis [2] and Frequency Modulation synthesis [3] to allow a range of complex audio spectra to be explored. Pitch, yaw and roll data from the left Myo are respectively mapped to the PAF synth's carrier frequency (ranging from 8.175-12543.9Hz), bandwidth and relative centre frequency. Pitch, yaw and roll data from the right Myo are respectively mapped to FM modulation frequency (relative to and ranging from 0.01-10 times the PAF carrier frequency), modulation depth (relative to and ranging from 0.01-10 times the PAF carrier frequency), and modulation wave shape (crossfading between sine, triangle, square, rising sawtooth and impulse). Data from the left and right Myo's EMG sensors are mapped respectively to amplitude control of the left and right audio channels, giving the performer control over the level and panning of the audio within the stereo field. By employing both positional and bio data, an embodied relationship between action and response is created; the gesture and the resulting sonic transformation become inextricably entwined.}
}

@inproceedings{nime19-music-Ahn,
  author = {Sabina Hyoju Ahn},
  title = {DIY Bionoise},
  pages = {17--20},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Federico Visi},
  year = {2019},
  month = {June},
  publisher = {UFRGS},
  address = {Porto Alegre, Brazil},
  URL = {http://www.nime.org/proceedings/2019/nime2019_music004.pdf},
  abstract = {DIY Bionoise (2018) is an instrument in which the performer can generate sound and noise, deriving from their own body. It contains a circuit that can measure the bioelectricity from living beings to control the instrument by tactile sense. This instrument has two functions – a modular synthesizer with an eight-step sequencer and a bionoise control mode.}
}

@inproceedings{nime19-music-Tom,
  author = {Ajin Tom},
  title = {FlexSynth – Blending Multi-Dimensional Sonic Scenes},
  pages = {21--24},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Federico Visi},
  year = {2019},
  month = {June},
  publisher = {UFRGS},
  address = {Porto Alegre, Brazil},
  URL = {http://www.nime.org/proceedings/2019/nime2019_music005.pdf},
  abstract = {FlexSynth is an interpretation of The Sponge, a DMI embedded with sensors to detect squeeze, flexion and torsion along with buttons to form an interface using which musical sounds are generated and the sound is sculpted. The key idea of the sponge is to harness the properties of a retractable, flexible object that gives the performer wide range of multi- parametric controls with high resolution in a maximized gesture space, considering its high manoeuvrability.}
}

@inproceedings{nime19-music-Tragtenberg,
  author = {João Tragtenberg, Filipe Calegario},
  title = {Gira},
  pages = {25--28},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Federico Visi},
  year = {2019},
  month = {June},
  publisher = {UFRGS},
  address = {Porto Alegre, Brazil},
  URL = {http://www.nime.org/proceedings/2019/nime2019_music006.pdf},
  abstract = {Gira is a music and dance performance with Giromin, a wearable wireless digital instrument. With this Digital Dance and Music Instrument a gesture is transformed into sound by motion sensors and an analog synthesizer. This transmutation of languages allows dance to generate music, which stimulates a new dance in an infinite feedback loop.}
}

@inproceedings{nime19-music-Cadiz,
  author = {Rodrigo F. Cádiz},
  title = {iCons},
  pages = {29--31},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Federico Visi},
  year = {2019},
  month = {June},
  publisher = {UFRGS},
  address = {Porto Alegre, Brazil},
  URL = {http://www.nime.org/proceedings/2019/nime2019_music007.pdf},
  abstract = {iCons is an interactive multi-channel music piece for live computer and a gesture sensor system designed by the composer especially for this piece, called AirTouch. Such system allows a much more musical approach to controlling sounds than the computer keyboard or mouse. Using only movements of the hands in the air it is possible to control most aspects of the music, such as sound shapes in time, loops, space positioning, or create very rich spectral densities.}
}

@inproceedings{nime19-music-Galvao,
  author = {Martim Galvão},
  title = {MusiCursor},
  pages = {32--34},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Federico Visi},
  year = {2019},
  month = {June},
  publisher = {UFRGS},
  address = {Porto Alegre, Brazil},
  URL = {http://www.nime.org/proceedings/2019/nime2019_music008.pdf},
  abstract = {MusiCursor is an interactive multimedia performance/interface that reimagines consumer-facing technologies as sites for creative expression. The piece draws inspiration from established UI/UX design paradigms and the role of the user in relation to these technologies. The performer assumes the role of a user installing a musically-driven navigation interface on their computer. After an installation prompt, they are guided through a series of demos, in which a software assistant instructs the performer to accomplish several tasks. Through their playing, the performer controls the cursor's navigation and clicking behavior. In lieu of a traditional score, the performer relies on text instructions and visual indicators from a software assistant. The software tracks the progress of the user throughout the piece and moves onto the next section only once a task has been completed. Each of the main tasks takes place on the web, where the user navigates across YouTube, Wikipedia, and Google Maps.}
}

@inproceedings{nime19-music-Cullen,
  author = {Barry Cullen and Miguel Ortiz and Paul Stapleton},
  title = {Pandemonium Trio perform Drone and Drama v2},
  pages = {35--38},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Federico Visi},
  year = {2019},
  month = {June},
  publisher = {UFRGS},
  address = {Porto Alegre, Brazil},
  URL = {http://www.nime.org/proceedings/2019/nime2019_music009.pdf},
  abstract = {Pandemonium Trio is Barry Cullen, Miguel Ortiz and Paul Stapleton. Our performance research trio has been set up to explore multiple instantiations of custom-made electronic instruments through improvisation. We are particularly interested in exploiting irregularities in the qualities of circuit components (e.g. imprecise tolerances/values), and how this allows for the development of stylistic differences across multiple instrument-performer configurations. We are also interested in how skill, style and performance techniques are developed in different ways on similar devices over extended periods of time, and how our existing musical practices are reconfigured through such collaborative exchanges.}
}

@inproceedings{nime19-music-DallAra-Majek,
  author = {Ana Dall'Ara-Majek and Takuto Fukuda},
  title = {Pythagorean Domino},
  pages = {39--42},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Federico Visi},
  year = {2019},
  month = {June},
  publisher = {UFRGS},
  address = {Porto Alegre, Brazil},
  URL = {http://www.nime.org/proceedings/2019/nime2019_music010.pdf},
  abstract = {Pythagorean Domino is an improvisatory composition composed in 2019 for an augmented Theremin and a gyro-based gestural controller. This work aims to integrate music concrete techniques and an algorithmic compositional approach in the context of composition for gestural controllers. While music concrete compositional practice brings out the concept of “composite object”—a sound object made up of several distinct and successive elements [1]—in the piece, our algorithmic compositional approach delivers an interpolation technique which entails gradual transformations of the composite objects over time. Our challenge is to perform a chain of short fragmental elements in tandem in the way to form a single musical unit, while the algorithms for transformation are autonomously changing synthetic and control parameter settings. This approach derives closely interconnected triangular interactions between two performers and a computer.}
}

@inproceedings{nime19-music-Nie,
  author = {Yiyao Nie},
  title = {River},
  pages = {43--46},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Federico Visi},
  year = {2019},
  month = {June},
  publisher = {UFRGS},
  address = {Porto Alegre, Brazil},
  URL = {http://www.nime.org/proceedings/2019/nime2019_music011.pdf},
  abstract = {“No one can step into the same river twice.” This instrument, named as River, contains rules and randomness. What exactly is music and how does it connect to and shape our form? Traditional musical instruments always have fixed physical forms that require performers to adjust to them. How about making a musical instrument that is more fluid and more expressive via deforming according to performers' movements? This was the question I attempted to explore when I started making this project. For this project, I combine the movement of dancing with music to present a fluid and dynamic shape of musical instrument. The fabric of this instrument can be separated as an extension to wash. It's portable, wireless, chargeable, stable and beautiful. This musical instrument generates sound by detecting different movements of the performer. It has four different modes selected by toggling the switches on the instrument interface. Each mode has different movement detection methods, generating various sound and music. Moreover, it can be played as a transmitting Tambourine. As for the music in my performance, it's all played by myself lively, consisting of different sound triggered and changed by performers' gestures and melody composed myself. Like the name of this instrument River, the four toggles and their detection methods and their corresponding generated sounds are intentionally designed. From simple node, beat, loop, drum, to various node, melody, music, the detection methods and their triggered sounds are becoming more and more complex and various, developing like a journey of a river.}
}

@inproceedings{nime19-music-Park,
  author = {Jiyun Park},
  title = {Self-Built Instrument (sound performance)},
  pages = {47--49},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Federico Visi},
  year = {2019},
  month = {June},
  publisher = {UFRGS},
  address = {Porto Alegre, Brazil},
  URL = {http://www.nime.org/proceedings/2019/nime2019_music012.pdf},
  abstract = {Self-Built Instrument project is focused on sound performance with an experi- mental instrument which is composed of strings and metallic sound box, pro- ducing overtones, harmonics and feed- back. It is capable to play with different sound colours : Resonances by cooper, bowing on strings, overtones and feed- back. All of factors triggers each other's sound. It is not a point to play a specific tone or to make a musical harmony, because the instrument is not able to per- fectly control. Playing this Instrument is a challenge to your capacity, such as gestures and sonic phenomenon following sense and space. The artist composed a piece and use few repertoire partly, however, mostly it is interesting to find what kind of sound comes to nest in mesh. The Artist tried to get over typical aesthetics of classical music, such as using precise pitches, melodies, and read scores. Instead of that, her approach towards to discover unusual sound elements which are considered as mistake in tradi- tional way. And play with them, for instance, strings without tuning, hitting a stuffs, unorganized pitch, also so-called clicker which happens unskilled.}
}

@inproceedings{nime19-music-Martins,
  author = {André L. Martins and Paulo Assis Barbosa},
  title = {Tanto Mar},
  pages = {50--51},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Federico Visi},
  year = {2019},
  month = {June},
  publisher = {UFRGS},
  address = {Porto Alegre, Brazil},
  URL = {http://www.nime.org/proceedings/2019/nime2019_music013.pdf},
  abstract = {"Tanto Mar" seeks to recreate the properties present in history between Portugal and Brazil, embracing the idea of an aqueous sound that dances and moves as much by cadence as by voluminous waves. The Atlantic Ocean, which separates and unites the two countries, serves as an inspiration for this quadraphonic performance, involving musical instruments and live electronics, where the sounds move through the four speakers. Each speaker symbolizes the paths that the sea travels uninterruptedly, in a unique dance of latitudes and longitudes. The intersection of sounds occurs through processes of reverberations, spatializations, echoes, modulations and grains that slowly form the sound material, composing, decomposing and manipulating the sound waves. Sound characters such as wind, oars, storms, calm, among others, are metaphorically evidenced through the sound material, creating a kind of rhythmic movement of a caravel at sea. The sounds of "Tanto Mar" move between entropy and chaos, between stillness and tsunami, between starboard and port, culminating in a textural dance where the objective is to take the listener away from electronic processing, and propose a dive in an intensified, attentive, deep and involving listening. New musical possibilities can happen through the experimentation of new routes, unusual routes and horizons not yet covered. The sea and its imprecise distances represent permanent challenges. "Tanto Mar" seeks to revive the feeling of the Portuguese poet Fernando Pessoa, when he wrote: "to dream even if it is impossible".}
}

@inproceedings{nime19-music-Carrascoza,
  author = {Cassia Carrascoza and Felipe Merker Castellani},
  title = {Tempo Transversal – Flauta Expandida},
  pages = {52--55},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Federico Visi},
  year = {2019},
  month = {June},
  publisher = {UFRGS},
  address = {Porto Alegre, Brazil},
  URL = {http://www.nime.org/proceedings/2019/nime2019_music014.pdf},
  abstract = {“Tempo Transversal – Flauta Expandida” aims to establish a computer- controlled catalyzer, which simultaneously combines and extends the flutist body actions, electronic sounds and the performative physical space. Some flute performance fragments, captured in real time by video cameras, besides pre-recorded images, built the visual projection. The flute player develops two pieces of experimental music for flute and electronic. All these heterogeneous elements are interrelated with each other in a network mediated by the computer. The result is a continuously unfolded interactive performance, which intends to manipulate settings of space-time perception. Brazilian contemporary repertoire for amplified bass flute and electronic sounds establishes the proposal.}
}

@inproceedings{nime19-music-Hamilton,
  author = {Rob Hamilton},
  title = {Trois Machins de la Grâce Aimante (Coretet no. 1)},
  pages = {56--59},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Federico Visi},
  year = {2019},
  month = {June},
  publisher = {UFRGS},
  address = {Porto Alegre, Brazil},
  URL = {http://www.nime.org/proceedings/2019/nime2019_music015.pdf},
  abstract = {Trois Machins de la Grâce Aimante is a composition intended to explore Twenty-First century technological and musical paradigms. At its heart Trois Machins is a string quartet fundamentally descended from a tradition that spans back to the 18th century. As such, the work primarily explores timbral material based around the sound of a bowed string, in this case realized using a set of physically modeled bowed strings controlled by Coretet, a virtual reality string instrument and networked performance environment. The composition - for four performers, preferably from an existing string quartet ensemble - takes the form of three distinct movements, each exploring different capabilities of the instrument itself and requiring different forms of communication and collaboration between the four performers.}
}

@inproceedings{nime19-music-Stapleton,
  author = {Paul Stapleton},
  title = {uncertain rhythms},
  pages = {60--62},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Federico Visi},
  year = {2019},
  month = {June},
  publisher = {UFRGS},
  address = {Porto Alegre, Brazil},
  URL = {http://www.nime.org/proceedings/2019/nime2019_music016.pdf},
  abstract = {This work is a continuation of my research into developing new performance ecosystems for improvisation. For this project I developed a new volatile assemblage, aka VOLA. My self-designed musical instruments are shaped by my history as a performer working in acoustic, mechanical, electronic and digital musics, blending and exploring the boundaries and breaking points of these different domains. My instruments support many of my existing techniques originally developed on more conventional instruments, while also affording the development of extended and novel techniques and performance strategies. In much of my work I am particularly focused on the exploration of musical timbre and texture; however, for this project my attention is also directed towards time, flow, pulse, duration, friction, disruption – in short, qualitative rhythms and defamiliarisation.}
}

@inproceedings{nime19-music-Erdem,
  author = {Çağri Erdem and Katja Henriksen Schia and Alexander Refsum Jensenius},
  title = {Vrengt: A Shared Body-Machine Instrument for Music-Dance Performance},
  pages = {63--65},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Federico Visi},
  year = {2019},
  month = {June},
  publisher = {UFRGS},
  address = {Porto Alegre, Brazil},
  URL = {http://www.nime.org/proceedings/2019/nime2019_music017.pdf},
  abstract = {What if a musician could step outside the familiar instrumental paradigm and adopt a new embodied language for moving through sound with a dancer in true partnership? And what if a dancer's body could coalesce with a musician's skills and intuitively render movements into instrumental actions for active sound- making? Vrengt is a multi-user instrument, specifically developed for music-dance performance, with a particular focus on exploring the boundaries between standstill vs motion, and silence vs sound. We sought for creating a work for one, hybrid corporeality, in which a dancer and a musician would co-creatively and co- dependently interact with their bodies and a machine. The challenge, then, was how could two performers with distinct embodied skills unite in a continuous entanglement of intentions, senses and experiences to control the same sonic and musical parameters? This was conceptually different than they had done before in the context of interactive dance performances.}
}

@inproceedings{nime19-music-Barbosa,
  author = {Paulo Assis Barbosa and Miguel Antar},
  title = {We Bass: inter(actions) on a hybrid instrument},
  pages = {66--67},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Federico Visi},
  year = {2019},
  month = {June},
  publisher = {UFRGS},
  address = {Porto Alegre, Brazil},
  URL = {http://www.nime.org/proceedings/2019/nime2019_music018.pdf},
  abstract = {The key for a collective process of free improvisation is the interaction, dependence and surrender of its parts, so the resulting sound flux is more than the sum of each individual layer. The We Bass performance is an exploration of the symbiosis of two performers playing the same instrument: Their actions have direct consequence on the resulting sound, challenging the other player with instability and interference. From the experiments of the English scientist Thomas Young (1773-1829) on the phenomena of diffraction and interference of light waves, we observe that interferences generated by overlapping light waves can have a character of annihilation, when they are out of phase (destructive interference), or a reinforcing character when in phase (constructive interference). From this reflection we try to deepen the discussion about the interferences of the performers inputs involved in a free improvisation session. We seek a model of connection between the performers that promotes processes of creation in the free improvisation, exploring the dialectics between reinforcement actions (processes of interaction that reinforces a certain sound moment) and movement actions (that destabilizes and transforms the flow). We Bass is a duo performance exploring the interactions between the musicians playing one hybrid machine: an electric upright bass guitar with live electronics processing. The instrument consists of an electric upright bass with movement sensors and a live processing machine with a controller that interacts with the sensors, changing some processing parameters and some controller mapping settings, creating an instable ground for the musicians.}
}

@inproceedings{nime19-music-introduction,
  author = {Federico Visi and Rodrigo Schramm},
  title = {Introduction},
  pages = {4},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Federico Visi},
  year = {2019},
  month = {June},
  publisher = {UFRGS},
  address = {Porto Alegre, Brazil},
  URL = {http://www.nime.org/proceedings/2019/nime2019_music00I.pdf},
}

@inproceedings{nime19-music-program,
  title = {NIME 2019 Concert Program},
  pages = {5},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Federico Visi},
  year = {2019},
  month = {June},
  publisher = {UFRGS},
  address = {Porto Alegre, Brazil},
  URL = {http://www.nime.org/proceedings/2019/nime2019_music0II.pdf},
}

@inproceedings{nime19-music-PC-members,
  title = {NIME 2019 Program Committee Members},
  pages = {6},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Federico Visi},
  year = {2019},
  month = {June},
  publisher = {UFRGS},
  address = {Porto Alegre, Brazil},
  URL = {http://www.nime.org/proceedings/2019/nime2019_musicIII.pdf},
}





